{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pyprojroot import here\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3134"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data in the previous step\n",
    "df = pd.read_pickle('..\\data\\processed\\data_clean.pkl')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3134 entries, 0 to 3133\n",
      "Data columns (total 16 columns):\n",
      " #   Column                         Non-Null Count  Dtype         \n",
      "---  ------                         --------------  -----         \n",
      " 0   project_title                  3134 non-null   object        \n",
      " 1   project_description            3134 non-null   object        \n",
      " 2   area_primary                   3129 non-null   object        \n",
      " 3   discipline_primary             3130 non-null   float64       \n",
      " 4   approval_date                  3134 non-null   datetime64[ns]\n",
      " 5   lead_research_institution      3134 non-null   object        \n",
      " 6   city                           3133 non-null   object        \n",
      " 7   ontario_commitment             3134 non-null   int32         \n",
      " 8   total_project_costs            3134 non-null   int32         \n",
      " 9   keyword                        1077 non-null   object        \n",
      " 10  year                           3134 non-null   int64         \n",
      " 11  month                          3134 non-null   int64         \n",
      " 12  label_total_project_costs      3134 non-null   int32         \n",
      " 13  label_ontario_commitment       3134 non-null   int32         \n",
      " 14  ontario_share                  3134 non-null   float64       \n",
      " 15  two_labela_ontario_commitment  3134 non-null   int32         \n",
      "dtypes: datetime64[ns](1), float64(2), int32(5), int64(2), object(6)\n",
      "memory usage: 330.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Split the data to train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1=df['label_total_project_costs'] #multiclass classifier model1\n",
    "y2=df['label_ontario_commitment'] #multiclass classifier model2\n",
    "y3=df['total_project_costs'] #regression model3\n",
    "y4=df['ontario_commitment']  # regression model 4\n",
    "y5=df['ontario_share']       #regression model 5\n",
    "y6=df['two_labela_ontario_commitment']\n",
    "x=df['project_title']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x,y):\n",
    "    x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=42)\n",
    "    return (x_train,x_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train1,y_test1 =split_data(x,y1)\n",
    "x_train,x_test,y_train2,y_test2 =split_data(x,y2)\n",
    "x_train,x_test,y_train3,y_test3 =split_data(x,y3)\n",
    "x_train,x_test,y_train4,y_test4 =split_data(x,y4)\n",
    "x_train,x_test,y_train5,y_test5 =split_data(x,y5)\n",
    "x_train,x_test,y_train6,y_test6 =split_data(x,y6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2350, 784)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train),len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2350,), (2350,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2855    system for flame synthesis collection and char...\n",
       "1644    centre for the evaluation of technological inn...\n",
       "2657    predictive immune monitoring approaches for pr...\n",
       "2765                            design observation studio\n",
       "518     biotechnology for wood fibre processing and en...\n",
       "                              ...                        \n",
       "3092    development of valueadded biodegradable multil...\n",
       "1095    experimental facility for advanced manufacturi...\n",
       "1130    neural and metabolic correlates of emotional p...\n",
       "1294                      watershed analysis and modeling\n",
       "860                    the ecological genomics laboratory\n",
       "Name: project_title, Length: 2350, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1. Make Tf-idf for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Atieh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvectorizer = TfidfVectorizer(analyzer='word',\n",
    "                             lowercase=True,\n",
    "                             max_df=0.9,\n",
    "                             min_df=2,\n",
    "                             ngram_range=(1,1),\n",
    "                             stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvectorizer.fit(x_train)\n",
    "tfidf_train = tfidfvectorizer.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test  = tfidfvectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2350, 1605), (784, 1605))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train.shape,tfidf_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "countvectorizer = CountVectorizer(analyzer= 'word', stop_words='english')\n",
    "count_wm=countvectorizer.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "count_tokens = countvectorizer.get_feature_names()\n",
    "tfidf_tokens = tfidfvectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizer\n",
      "\n",
      "      1000mhz  120c  1861  1871  18752010  1891  1d  20  2020  2d  ...  york  \\\n",
      "0           0     0     0     0         0     0   0   0     0   0  ...     0   \n",
      "1           0     0     0     0         0     0   0   0     0   0  ...     0   \n",
      "2           0     0     0     0         0     0   0   0     0   0  ...     0   \n",
      "3           0     0     0     0         0     0   0   0     0   0  ...     0   \n",
      "4           0     0     0     0         0     0   0   0     0   0  ...     0   \n",
      "...       ...   ...   ...   ...       ...   ...  ..  ..   ...  ..  ...   ...   \n",
      "2345        0     0     0     0         0     0   0   0     0   0  ...     0   \n",
      "2346        0     0     0     0         0     0   0   0     0   0  ...     0   \n",
      "2347        0     0     0     0         0     0   0   0     0   0  ...     0   \n",
      "2348        0     0     0     0         0     0   0   0     0   0  ...     0   \n",
      "2349        0     0     0     0         0     0   0   0     0   0  ...     0   \n",
      "\n",
      "      young  youth  yukon  zebrafish  zero  zincdependent  zone  zoonoses  \\\n",
      "0         0      0      0          0     0              0     0         0   \n",
      "1         0      0      0          0     0              0     0         0   \n",
      "2         0      0      0          0     0              0     0         0   \n",
      "3         0      0      0          0     0              0     0         0   \n",
      "4         0      0      0          0     0              0     0         0   \n",
      "...     ...    ...    ...        ...   ...            ...   ...       ...   \n",
      "2345      0      0      0          0     0              0     0         0   \n",
      "2346      0      0      0          0     0              0     0         0   \n",
      "2347      0      0      0          0     0              0     0         0   \n",
      "2348      0      0      0          0     0              0     0         0   \n",
      "2349      0      0      0          0     0              0     0         0   \n",
      "\n",
      "      zoonotic  \n",
      "0            0  \n",
      "1            0  \n",
      "2            0  \n",
      "3            0  \n",
      "4            0  \n",
      "...        ...  \n",
      "2345         0  \n",
      "2346         0  \n",
      "2347         0  \n",
      "2348         0  \n",
      "2349         0  \n",
      "\n",
      "[2350 rows x 4117 columns]\n",
      "\n",
      "TD-IDF Vectorizer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_countvect = pd.DataFrame(data = count_wm.toarray(),columns = count_tokens)\n",
    "df_tfidfvect = pd.DataFrame(data = tfidf_train.toarray(),columns = tfidf_tokens)\n",
    "print(\"Count Vectorizer\\n\")\n",
    "print(df_countvect)\n",
    "print(\"\\nTD-IDF Vectorizer\\n\")\n",
    "#print(df_tfidfvect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2350, 1605), (784, 1605))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train.shape, tfidf_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1605"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1605"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(tfidf_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit change and fit the model\n",
    "#transform just return the value of known model\n",
    "type(tfidf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['associated',\n",
       " 'assurance',\n",
       " 'asthma',\n",
       " 'astronomical',\n",
       " 'astronomy',\n",
       " 'astrophysics',\n",
       " 'asymmetric',\n",
       " 'atmosphere',\n",
       " 'atmospheric',\n",
       " 'atomic',\n",
       " 'atomicallyresolved',\n",
       " 'atoms',\n",
       " 'attention',\n",
       " 'attosecond',\n",
       " 'autism',\n",
       " 'automated',\n",
       " 'automation',\n",
       " 'automotive',\n",
       " 'autonomic',\n",
       " 'autonomous',\n",
       " 'avian',\n",
       " 'aviation',\n",
       " 'awareness',\n",
       " 'background',\n",
       " 'bacteria',\n",
       " 'bacterial',\n",
       " 'bacteriophages',\n",
       " 'balance',\n",
       " 'barriers',\n",
       " 'based',\n",
       " 'basic',\n",
       " 'basis',\n",
       " 'beamline',\n",
       " 'behavior',\n",
       " 'behavioral',\n",
       " 'behaviors',\n",
       " 'behaviour',\n",
       " 'behavioural',\n",
       " 'benefit',\n",
       " 'best',\n",
       " 'beta',\n",
       " 'beverage',\n",
       " 'big',\n",
       " 'bilingual',\n",
       " 'bioactive',\n",
       " 'bioanalytical',\n",
       " 'bioarchaeology',\n",
       " 'biochemical',\n",
       " 'biochemistry',\n",
       " 'biodiversity',\n",
       " 'bioengineering',\n",
       " 'biofilm',\n",
       " 'biofuel',\n",
       " 'biogeochemical',\n",
       " 'biogeochemistry',\n",
       " 'bioimaging',\n",
       " 'bioinformatics',\n",
       " 'biological',\n",
       " 'biology',\n",
       " 'biomarker',\n",
       " 'biomarkers',\n",
       " 'biomass',\n",
       " 'biomaterial',\n",
       " 'biomaterials',\n",
       " 'biomatrix',\n",
       " 'biomechanical',\n",
       " 'biomechanics',\n",
       " 'biomedical',\n",
       " 'biomedicine',\n",
       " 'biomimetic',\n",
       " 'biomolecular',\n",
       " 'bioorganic',\n",
       " 'biophotonics',\n",
       " 'biophysical',\n",
       " 'biophysics',\n",
       " 'biopolymers',\n",
       " 'bioproducts',\n",
       " 'biorefinery',\n",
       " 'biosensors',\n",
       " 'biotechnology',\n",
       " 'birds',\n",
       " 'block',\n",
       " 'blood',\n",
       " 'body',\n",
       " 'bone',\n",
       " 'boreal',\n",
       " 'brain',\n",
       " 'breast',\n",
       " 'breeding',\n",
       " 'bridging',\n",
       " 'broad',\n",
       " 'broadband',\n",
       " 'bronchopulmonary',\n",
       " 'bubble',\n",
       " 'building',\n",
       " 'built',\n",
       " 'bulk',\n",
       " 'buried',\n",
       " 'business',\n",
       " 'calcium',\n",
       " 'calibration',\n",
       " 'calorimetry',\n",
       " 'campus',\n",
       " 'canada',\n",
       " 'canadas',\n",
       " 'canadian',\n",
       " 'cancer',\n",
       " 'cancerrelated',\n",
       " 'cancers',\n",
       " 'cannabinoid',\n",
       " 'capabilities',\n",
       " 'capacity',\n",
       " 'capture',\n",
       " 'carbon',\n",
       " 'cardiac',\n",
       " 'cardiometabolic',\n",
       " 'cardiopulmonary',\n",
       " 'cardiovascular',\n",
       " 'care',\n",
       " 'carleton',\n",
       " 'cartilage',\n",
       " 'catalysis',\n",
       " 'catalyst',\n",
       " 'catalysts',\n",
       " 'catalytic',\n",
       " 'catchment',\n",
       " 'cattle',\n",
       " 'cell',\n",
       " 'cellmediated',\n",
       " 'cells',\n",
       " 'cellular',\n",
       " 'census',\n",
       " 'center',\n",
       " 'centre',\n",
       " 'cerebral',\n",
       " 'cerebrovascular',\n",
       " 'chair',\n",
       " 'chamber',\n",
       " 'chambers',\n",
       " 'change',\n",
       " 'changes',\n",
       " 'changing',\n",
       " 'channel',\n",
       " 'channels',\n",
       " 'characterization',\n",
       " 'characterizing',\n",
       " 'chemical',\n",
       " 'chemicals',\n",
       " 'chemistry',\n",
       " 'child',\n",
       " 'childhood',\n",
       " 'children',\n",
       " 'childrens',\n",
       " 'chiral',\n",
       " 'chromatin',\n",
       " 'chromatograph',\n",
       " 'chromatography',\n",
       " 'chromosome',\n",
       " 'chronic',\n",
       " 'cinema',\n",
       " 'circuit',\n",
       " 'circuits',\n",
       " 'cities',\n",
       " 'clean',\n",
       " 'climate',\n",
       " 'clinical',\n",
       " 'cloud',\n",
       " 'cluster',\n",
       " 'clustering',\n",
       " 'cns',\n",
       " 'co2',\n",
       " 'coating',\n",
       " 'cognition',\n",
       " 'cognitive',\n",
       " 'coherent',\n",
       " 'cold',\n",
       " 'collaboration',\n",
       " 'collaborative',\n",
       " 'collection',\n",
       " 'college',\n",
       " 'colon',\n",
       " 'combating',\n",
       " 'combined',\n",
       " 'combining',\n",
       " 'combustion',\n",
       " 'communication',\n",
       " 'communications',\n",
       " 'communities',\n",
       " 'community',\n",
       " 'comparative',\n",
       " 'complex',\n",
       " 'complexes',\n",
       " 'complexity',\n",
       " 'complications',\n",
       " 'components',\n",
       " 'composites',\n",
       " 'composition',\n",
       " 'compounds',\n",
       " 'comprehensive',\n",
       " 'computational',\n",
       " 'computer',\n",
       " 'computerassisted',\n",
       " 'computerintensive',\n",
       " 'computing',\n",
       " 'concepts',\n",
       " 'conditions',\n",
       " 'confocal',\n",
       " 'connecting',\n",
       " 'consequences',\n",
       " 'conservation',\n",
       " 'consortium',\n",
       " 'constraining',\n",
       " 'consumer',\n",
       " 'containment',\n",
       " 'contaminant',\n",
       " 'contaminants',\n",
       " 'contaminated',\n",
       " 'contamination',\n",
       " 'contemporary',\n",
       " 'content',\n",
       " 'context',\n",
       " 'continuous',\n",
       " 'continuum',\n",
       " 'contrast',\n",
       " 'contributions',\n",
       " 'control',\n",
       " 'controlled',\n",
       " 'convergence',\n",
       " 'conversion',\n",
       " 'copolymers',\n",
       " 'cord',\n",
       " 'core',\n",
       " 'correlates',\n",
       " 'corrosion',\n",
       " 'cortex',\n",
       " 'cortical',\n",
       " 'cost',\n",
       " 'coupled',\n",
       " 'cracking',\n",
       " 'crc',\n",
       " 'creating',\n",
       " 'creation',\n",
       " 'creative',\n",
       " 'critical',\n",
       " 'critically',\n",
       " 'crops',\n",
       " 'crosstalk',\n",
       " 'cryoelectron',\n",
       " 'cryogenic',\n",
       " 'cryospheric',\n",
       " 'crystal',\n",
       " 'crystallization',\n",
       " 'crystallography',\n",
       " 'culinary',\n",
       " 'cultural',\n",
       " 'culture',\n",
       " 'cuttingedge',\n",
       " 'cyberphysical',\n",
       " 'cybersecurity',\n",
       " 'cycle',\n",
       " 'cycles',\n",
       " 'cyclic',\n",
       " 'cytometer',\n",
       " 'cytometry',\n",
       " 'daily',\n",
       " 'damage',\n",
       " 'dark',\n",
       " 'data',\n",
       " 'database',\n",
       " 'dataintensive',\n",
       " 'death',\n",
       " 'decay',\n",
       " 'deciphering',\n",
       " 'decision',\n",
       " 'decoding',\n",
       " 'defining',\n",
       " 'deformation',\n",
       " 'degeneration',\n",
       " 'degradation',\n",
       " 'delivery',\n",
       " 'department',\n",
       " 'deposition',\n",
       " 'depression',\n",
       " 'des',\n",
       " 'design',\n",
       " 'detection',\n",
       " 'detector',\n",
       " 'detectors',\n",
       " 'deterioration',\n",
       " 'determinants',\n",
       " 'determination',\n",
       " 'determine',\n",
       " 'develop',\n",
       " 'developing',\n",
       " 'development',\n",
       " 'developmental',\n",
       " 'developments',\n",
       " 'device',\n",
       " 'devices',\n",
       " 'diabetes',\n",
       " 'diagnosis',\n",
       " 'diagnostic',\n",
       " 'diagnostics',\n",
       " 'diet',\n",
       " 'dietary',\n",
       " 'differences',\n",
       " 'differential',\n",
       " 'differentiation',\n",
       " 'diffraction',\n",
       " 'diffractometer',\n",
       " 'digital',\n",
       " 'dimensional',\n",
       " 'direct',\n",
       " 'discover',\n",
       " 'discoveries',\n",
       " 'discovering',\n",
       " 'discovery',\n",
       " 'disease',\n",
       " 'diseased',\n",
       " 'diseases',\n",
       " 'disorders',\n",
       " 'dissecting',\n",
       " 'dissection',\n",
       " 'dissemination',\n",
       " 'distributed',\n",
       " 'distribution',\n",
       " 'diversity',\n",
       " 'dna',\n",
       " 'domain',\n",
       " 'dose',\n",
       " 'double',\n",
       " 'drinking',\n",
       " 'drive',\n",
       " 'driver',\n",
       " 'driving',\n",
       " 'drosophila',\n",
       " 'drug',\n",
       " 'drugs',\n",
       " 'dynamic',\n",
       " 'dynamics',\n",
       " 'dysfunction',\n",
       " 'dysplasia',\n",
       " 'early',\n",
       " 'earth',\n",
       " 'earthquake',\n",
       " 'ecohydrology',\n",
       " 'ecological',\n",
       " 'ecology',\n",
       " 'economic',\n",
       " 'ecophysiology',\n",
       " 'ecosystem',\n",
       " 'ecosystems',\n",
       " 'edge',\n",
       " 'education',\n",
       " 'eeg',\n",
       " 'effect',\n",
       " 'effective',\n",
       " 'effects',\n",
       " 'efficacy',\n",
       " 'efficiency',\n",
       " 'electric',\n",
       " 'electrical',\n",
       " 'electrochemical',\n",
       " 'electrochemistry',\n",
       " 'electromagnetic',\n",
       " 'electron',\n",
       " 'electronic',\n",
       " 'electronics',\n",
       " 'electrophysiological',\n",
       " 'electrophysiology',\n",
       " 'elegans',\n",
       " 'element',\n",
       " 'elements',\n",
       " 'elucidate',\n",
       " 'elucidating',\n",
       " 'elucidation',\n",
       " 'embedded',\n",
       " 'embodied',\n",
       " 'embryonic',\n",
       " 'emergency',\n",
       " 'emerging',\n",
       " 'emission',\n",
       " 'emissions',\n",
       " 'emotional',\n",
       " 'emotions',\n",
       " 'en',\n",
       " 'enable',\n",
       " 'enabled',\n",
       " 'enabling',\n",
       " 'endocrine',\n",
       " 'endstations',\n",
       " 'energy',\n",
       " 'engineered',\n",
       " 'engineering',\n",
       " 'enhance',\n",
       " 'enhanced',\n",
       " 'enhancement',\n",
       " 'enhancing',\n",
       " 'entry',\n",
       " 'environment',\n",
       " 'environmental',\n",
       " 'environmentally',\n",
       " 'environments',\n",
       " 'enzymes',\n",
       " 'epidemic',\n",
       " 'epigenetic',\n",
       " 'epigenetics',\n",
       " 'epilepsy',\n",
       " 'epithelial',\n",
       " 'equipment',\n",
       " 'equity',\n",
       " 'era',\n",
       " 'ergonomics',\n",
       " 'establish',\n",
       " 'establishing',\n",
       " 'establishment',\n",
       " 'et',\n",
       " 'ethnography',\n",
       " 'evaluate',\n",
       " 'evaluating',\n",
       " 'evaluation',\n",
       " 'events',\n",
       " 'evidencebased',\n",
       " 'evolution',\n",
       " 'evolutionary',\n",
       " 'examining',\n",
       " 'excellence',\n",
       " 'exchange',\n",
       " 'exercise',\n",
       " 'existing',\n",
       " 'expanded',\n",
       " 'expanding',\n",
       " 'expansion',\n",
       " 'experience',\n",
       " 'experimental',\n",
       " 'experimentation',\n",
       " 'experiments',\n",
       " 'exploration',\n",
       " 'explore',\n",
       " 'exploring',\n",
       " 'expression',\n",
       " 'extending',\n",
       " 'extracellular',\n",
       " 'extraction',\n",
       " 'extreme',\n",
       " 'eye',\n",
       " 'fabrication',\n",
       " 'face',\n",
       " 'facilitate',\n",
       " 'facilities',\n",
       " 'facility',\n",
       " 'factor',\n",
       " 'factors',\n",
       " 'faculty',\n",
       " 'failure',\n",
       " 'fair',\n",
       " 'falls',\n",
       " 'families',\n",
       " 'fast',\n",
       " 'fat',\n",
       " 'fate',\n",
       " 'fault',\n",
       " 'features',\n",
       " 'feedback',\n",
       " 'femtosecond',\n",
       " 'fermentation',\n",
       " 'fetal',\n",
       " 'fibre',\n",
       " 'fibroblasts',\n",
       " 'fibrosis',\n",
       " 'field',\n",
       " 'fight',\n",
       " 'film',\n",
       " 'films',\n",
       " 'fish',\n",
       " 'fixation',\n",
       " 'flexible',\n",
       " 'flight',\n",
       " 'flow',\n",
       " 'flows',\n",
       " 'fluid',\n",
       " 'fluids',\n",
       " 'fluorescence',\n",
       " 'fluorescent',\n",
       " 'fluoroscopy',\n",
       " 'flux',\n",
       " 'focused',\n",
       " 'following',\n",
       " 'food',\n",
       " 'foods',\n",
       " 'force',\n",
       " 'forensic',\n",
       " 'forensics',\n",
       " 'forest',\n",
       " 'forests',\n",
       " 'formation',\n",
       " 'fossil',\n",
       " 'fracture',\n",
       " 'fracturing',\n",
       " 'frequency',\n",
       " 'freshwater',\n",
       " 'fuel',\n",
       " 'fullscale',\n",
       " 'function',\n",
       " 'functional',\n",
       " 'functionality',\n",
       " 'functionally',\n",
       " 'functions',\n",
       " 'fundamental',\n",
       " 'fungal',\n",
       " 'fusion',\n",
       " 'future',\n",
       " 'gait',\n",
       " 'gaming',\n",
       " 'gap',\n",
       " 'gas',\n",
       " 'gastrointestinal',\n",
       " 'gender',\n",
       " 'gene',\n",
       " 'generate',\n",
       " 'generation',\n",
       " 'genes',\n",
       " 'genetic',\n",
       " 'genetically',\n",
       " 'genetics',\n",
       " 'genome',\n",
       " 'genomes',\n",
       " 'genomic',\n",
       " 'genomics',\n",
       " 'geochemical',\n",
       " 'geographic',\n",
       " 'geologic',\n",
       " 'geological',\n",
       " 'geomatics',\n",
       " 'geophysical',\n",
       " 'geosynthetics',\n",
       " 'geotechnical',\n",
       " 'glacier',\n",
       " 'global',\n",
       " 'globalization',\n",
       " 'governance',\n",
       " 'governing',\n",
       " 'gpcr',\n",
       " 'gprotein',\n",
       " 'gpu',\n",
       " 'grant',\n",
       " 'graphene',\n",
       " 'gravimetry',\n",
       " 'gravity',\n",
       " 'great',\n",
       " 'green',\n",
       " 'greenhouse',\n",
       " 'grid',\n",
       " 'grids',\n",
       " 'groundwater',\n",
       " 'groundwatercoastal',\n",
       " 'groups',\n",
       " 'growth',\n",
       " 'guelph',\n",
       " 'guided',\n",
       " 'gut',\n",
       " 'hand',\n",
       " 'haptic',\n",
       " 'hardware',\n",
       " 'hardwareintheloop',\n",
       " 'harnessing',\n",
       " 'harvesting',\n",
       " 'health',\n",
       " 'healthcare',\n",
       " 'hearing',\n",
       " 'heart',\n",
       " 'hemodynamic',\n",
       " 'hemodynamics',\n",
       " 'hemostasis',\n",
       " 'heterogeneous',\n",
       " 'high',\n",
       " 'highcapacity',\n",
       " 'highcontent',\n",
       " 'highdimensional',\n",
       " 'higherorder',\n",
       " 'highperformance',\n",
       " 'highresolution',\n",
       " 'highspeed',\n",
       " 'highthroughput',\n",
       " 'history',\n",
       " 'hiv',\n",
       " 'holistic',\n",
       " 'homeostasis',\n",
       " 'horizons',\n",
       " 'hormonal',\n",
       " 'hormone',\n",
       " 'host',\n",
       " 'hostpathogen',\n",
       " 'hosts',\n",
       " 'house',\n",
       " 'human',\n",
       " 'humanities',\n",
       " 'humans',\n",
       " 'hybrid',\n",
       " 'hydraulic',\n",
       " 'hydrogen',\n",
       " 'hydrology',\n",
       " 'hyperpolarized',\n",
       " 'hyperspectral',\n",
       " 'hypertension',\n",
       " 'ice',\n",
       " 'identification',\n",
       " 'identify',\n",
       " 'identifying',\n",
       " 'identity',\n",
       " 'ii',\n",
       " 'ill',\n",
       " 'illness',\n",
       " 'image',\n",
       " 'imageguided',\n",
       " 'imaging',\n",
       " 'immersive',\n",
       " 'immune',\n",
       " 'immunity',\n",
       " 'impact',\n",
       " 'impacts',\n",
       " 'impairment',\n",
       " 'implant',\n",
       " 'implementation',\n",
       " 'implications',\n",
       " 'important',\n",
       " 'improve',\n",
       " 'improved',\n",
       " 'improving',\n",
       " 'increasing',\n",
       " 'indigenous',\n",
       " 'indirect',\n",
       " 'individual',\n",
       " 'induced',\n",
       " 'industrial',\n",
       " 'industries',\n",
       " 'industry',\n",
       " 'infant',\n",
       " 'infants',\n",
       " 'infection',\n",
       " 'infectious',\n",
       " 'inflammation',\n",
       " 'inflammatory',\n",
       " 'influence',\n",
       " 'information',\n",
       " 'infrared',\n",
       " 'infrastructure',\n",
       " 'initiative',\n",
       " 'injury',\n",
       " 'innate',\n",
       " 'innovation',\n",
       " 'innovations',\n",
       " 'innovative',\n",
       " 'inorganic',\n",
       " 'input',\n",
       " 'insights',\n",
       " 'insitu',\n",
       " 'instability',\n",
       " 'institute',\n",
       " 'instrument',\n",
       " 'instrumentation',\n",
       " 'insulin',\n",
       " 'integrated',\n",
       " 'integrating',\n",
       " 'integration',\n",
       " 'integrative',\n",
       " 'intelligence',\n",
       " 'intelligent',\n",
       " 'intense',\n",
       " 'intensive',\n",
       " 'interaction',\n",
       " 'interactions',\n",
       " 'interactive',\n",
       " 'interdisciplinary',\n",
       " 'interface',\n",
       " 'interfaces',\n",
       " 'interfacial',\n",
       " 'interference',\n",
       " 'interiors',\n",
       " 'international',\n",
       " 'internet',\n",
       " 'interpersonal',\n",
       " 'intervention',\n",
       " 'interventional',\n",
       " 'interventions',\n",
       " 'intestinal',\n",
       " 'intracellular',\n",
       " 'invasion',\n",
       " 'invasive',\n",
       " 'investigate',\n",
       " 'investigating',\n",
       " 'investigation',\n",
       " 'investigations',\n",
       " 'involved',\n",
       " 'involving',\n",
       " 'ion',\n",
       " 'ions',\n",
       " 'islet',\n",
       " 'isolation',\n",
       " 'isotope',\n",
       " 'isotopic',\n",
       " 'joining',\n",
       " 'joint',\n",
       " 'key',\n",
       " 'kidney',\n",
       " 'killer',\n",
       " 'knee',\n",
       " 'knowledge',\n",
       " 'la',\n",
       " 'lab',\n",
       " 'laboratories',\n",
       " 'laboratory',\n",
       " 'labs',\n",
       " 'lake',\n",
       " 'lakehead',\n",
       " 'lakes',\n",
       " 'land',\n",
       " 'landscape',\n",
       " 'language',\n",
       " 'large',\n",
       " 'largescale',\n",
       " 'laser',\n",
       " 'lateral',\n",
       " 'law',\n",
       " 'layered',\n",
       " 'leading',\n",
       " 'learning',\n",
       " 'legal',\n",
       " 'leukemic',\n",
       " 'level',\n",
       " 'levels',\n",
       " 'life',\n",
       " 'lifespan',\n",
       " 'light',\n",
       " 'lightweight',\n",
       " 'limits',\n",
       " 'link',\n",
       " 'linking',\n",
       " 'lipids',\n",
       " 'liquid',\n",
       " 'literature',\n",
       " 'live',\n",
       " 'livecell',\n",
       " 'living',\n",
       " 'load',\n",
       " 'loading',\n",
       " 'loads',\n",
       " 'local',\n",
       " 'loci',\n",
       " 'locomotion',\n",
       " 'locomotor',\n",
       " 'long',\n",
       " 'longitudinal',\n",
       " 'longterm',\n",
       " 'loss',\n",
       " 'low',\n",
       " 'lung',\n",
       " 'machine',\n",
       " 'machines',\n",
       " 'macromolecular',\n",
       " 'magnetic',\n",
       " 'making',\n",
       " 'mammalian',\n",
       " 'management',\n",
       " 'manipulating',\n",
       " 'manipulation',\n",
       " 'manufacture',\n",
       " 'manufacturing',\n",
       " 'map',\n",
       " 'mapping',\n",
       " 'marine',\n",
       " 'maritime',\n",
       " 'markers',\n",
       " 'mass',\n",
       " 'material',\n",
       " 'materials',\n",
       " 'maternal',\n",
       " 'mathematical',\n",
       " 'mathematics',\n",
       " 'matrix',\n",
       " 'matter',\n",
       " 'mcmaster',\n",
       " 'measurement',\n",
       " 'measurements',\n",
       " 'measuring',\n",
       " 'mechanical',\n",
       " 'mechanics',\n",
       " 'mechanism',\n",
       " 'mechanisms',\n",
       " 'mechanistic',\n",
       " 'media',\n",
       " 'mediated',\n",
       " 'medical',\n",
       " 'medicine',\n",
       " 'melanoma',\n",
       " 'membrane',\n",
       " 'membranes',\n",
       " 'memory',\n",
       " 'mental',\n",
       " 'metabolic',\n",
       " 'metabolism',\n",
       " 'metabolome',\n",
       " 'metabolomics',\n",
       " 'metal',\n",
       " 'metallic',\n",
       " 'metals',\n",
       " 'metamaterials',\n",
       " 'metastasis',\n",
       " 'methodologies',\n",
       " 'methods',\n",
       " 'mhz',\n",
       " 'mice',\n",
       " 'micro',\n",
       " 'microbeam',\n",
       " 'microbes',\n",
       " 'microbial',\n",
       " 'microbiology',\n",
       " 'microbiome',\n",
       " 'microbiota',\n",
       " 'microcellular',\n",
       " 'microdata',\n",
       " 'microenvironment',\n",
       " 'microfluidic',\n",
       " 'microfluidics',\n",
       " 'microorganisms',\n",
       " 'microparticles',\n",
       " 'microscale',\n",
       " 'microscope',\n",
       " 'microscopic',\n",
       " 'microscopy',\n",
       " 'microstructure',\n",
       " 'microsystems',\n",
       " 'microvascular',\n",
       " 'microwave',\n",
       " 'migration',\n",
       " 'milk',\n",
       " 'mind',\n",
       " 'mining',\n",
       " 'mitigating',\n",
       " 'mitochondrial',\n",
       " 'mixed',\n",
       " 'mixtures',\n",
       " 'mobile',\n",
       " 'mobility',\n",
       " 'mobilizing',\n",
       " 'model',\n",
       " 'modelbased',\n",
       " 'modeling',\n",
       " 'modelling',\n",
       " 'models',\n",
       " 'modern',\n",
       " 'modification',\n",
       " 'modifications',\n",
       " 'modulation',\n",
       " 'modulators',\n",
       " 'molecular',\n",
       " 'molecule',\n",
       " 'molecules',\n",
       " 'monitor',\n",
       " 'monitoring',\n",
       " 'monoclonal',\n",
       " 'monolayers',\n",
       " 'morphology',\n",
       " 'motion',\n",
       " 'motivation',\n",
       " 'motor',\n",
       " 'mouse',\n",
       " 'movement',\n",
       " 'movements',\n",
       " 'mri',\n",
       " 'mrs',\n",
       " 'multidimensional',\n",
       " 'multidisciplinary',\n",
       " 'multielement',\n",
       " 'multifunctional',\n",
       " 'multimaterial',\n",
       " 'multimedia',\n",
       " 'multimodal',\n",
       " 'multiphase',\n",
       " 'multiple',\n",
       " 'multiscale',\n",
       " 'multisensory',\n",
       " 'muscle',\n",
       " 'musculoskeletal',\n",
       " 'music',\n",
       " 'mutation',\n",
       " 'mutations',\n",
       " 'myogenic',\n",
       " 'nano',\n",
       " 'nanofabrication',\n",
       " 'nanomaterial',\n",
       " 'nanomaterials',\n",
       " 'nanoparticle',\n",
       " 'nanoparticles',\n",
       " 'nanophotonics',\n",
       " 'nanoscale',\n",
       " 'nanostructured',\n",
       " 'nanostructures',\n",
       " 'nanosystems',\n",
       " 'nanotechnology',\n",
       " 'national',\n",
       " 'natural',\n",
       " 'neonatal',\n",
       " 'network',\n",
       " 'networking',\n",
       " 'networks',\n",
       " 'neural',\n",
       " 'neurobiology',\n",
       " 'neurochemistry',\n",
       " 'neurocognitive',\n",
       " 'neurodegeneration',\n",
       " 'neurodegenerative',\n",
       " 'neuroendocrinology',\n",
       " 'neurogenesis',\n",
       " 'neurogenetics',\n",
       " 'neuroimaging',\n",
       " 'neurological',\n",
       " 'neuromodulation',\n",
       " 'neuromuscular',\n",
       " 'neuronal',\n",
       " 'neurons',\n",
       " 'neuroplasticity',\n",
       " 'neuroscience',\n",
       " 'neutrinos',\n",
       " 'neutron',\n",
       " 'new',\n",
       " 'nextgeneration',\n",
       " 'niagara',\n",
       " 'nickel',\n",
       " 'nipissing',\n",
       " 'nmda',\n",
       " 'nmr',\n",
       " 'noble',\n",
       " 'noninvasive',\n",
       " 'nonlinear',\n",
       " 'normal',\n",
       " 'north',\n",
       " 'northern',\n",
       " 'novel',\n",
       " 'nuclear',\n",
       " 'numerical',\n",
       " 'nutrient',\n",
       " 'nutrition',\n",
       " 'obesity',\n",
       " 'object',\n",
       " 'observation',\n",
       " 'observatory',\n",
       " 'observing',\n",
       " 'obstructive',\n",
       " 'occupational',\n",
       " 'older',\n",
       " 'oncogenic',\n",
       " 'oncology',\n",
       " 'online',\n",
       " 'onroad',\n",
       " 'ontario',\n",
       " 'ontarios',\n",
       " 'open',\n",
       " 'operating',\n",
       " 'operation',\n",
       " 'optical',\n",
       " 'optics',\n",
       " 'optimal',\n",
       " 'optimization',\n",
       " 'optimizing',\n",
       " 'optoelectronic',\n",
       " 'optoelectronics',\n",
       " 'oral',\n",
       " 'organ',\n",
       " 'organelle',\n",
       " 'organic',\n",
       " 'organisms',\n",
       " 'organization',\n",
       " 'organizational',\n",
       " 'organonachip',\n",
       " 'origins',\n",
       " 'orthopaedic',\n",
       " 'osteoarthritis',\n",
       " 'ottawa',\n",
       " 'outcomes',\n",
       " 'ovarian',\n",
       " 'overcoming',\n",
       " 'oxidation',\n",
       " 'oxygen',\n",
       " 'paediatric',\n",
       " 'pain',\n",
       " 'paleoecology',\n",
       " 'paradigm',\n",
       " 'parallel',\n",
       " 'parameters',\n",
       " 'participatory',\n",
       " 'particle',\n",
       " 'pathogenesis',\n",
       " 'pathogenic',\n",
       " 'pathogens',\n",
       " 'pathology',\n",
       " 'pathophysiology',\n",
       " 'pathway',\n",
       " 'pathways',\n",
       " 'patient',\n",
       " ...]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_tokens[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1446,  993,  278, ...,  811,  628,  446], dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train.nonzero()[1] #Return the indices of the elements that are non-zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0,    0,    0, ..., 2349, 2349, 2349], dtype=int32),\n",
       " array([1446,  993,  278, ...,  811,  628,  446], dtype=int32))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[3, 0, 4],\n",
       "        [4, 7, 0]]),\n",
       " (array([0, 0, 1, 1], dtype=int64), array([0, 2, 0, 1], dtype=int64)))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a=np.array([[3,0,4],[4,7,0]])\n",
    "a, a.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.nonzero()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2350, 1605)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf_tokens</th>\n",
       "      <th>tf-idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>modulation</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>attosecond</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>infrastructure</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>array</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>computing</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>learning</td>\n",
       "      <td>0.701984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>adolescent</td>\n",
       "      <td>0.701680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>leading</td>\n",
       "      <td>0.700922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>public</td>\n",
       "      <td>0.700793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>assistive</td>\n",
       "      <td>0.700316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tfidf_tokens    tf-idf\n",
       "119      modulation  1.000000\n",
       "31       attosecond  1.000000\n",
       "328  infrastructure  1.000000\n",
       "187           array  1.000000\n",
       "267       computing  1.000000\n",
       "..              ...       ...\n",
       "330        learning  0.701984\n",
       "308      adolescent  0.701680\n",
       "13          leading  0.700922\n",
       "136          public  0.700793\n",
       "60        assistive  0.700316\n",
       "\n",
       "[344 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract the words for with the tf-idf of higher than 0.7 for train set.\n",
    "m=0\n",
    "d=[]\n",
    "for col in tfidf_train.nonzero()[1]:\n",
    "    if tfidf_train[tfidf_train.nonzero()[0][m],col] > 0.7:\n",
    "        #print (words[col], '-', tfidf_train[tfidf_train.nonzero()[0][m],col])\n",
    "        d.append((tfidf_tokens[col],tfidf_train[tfidf_train.nonzero()[0][m],col]))\n",
    "        m=m+1\n",
    "    else:\n",
    "        m=m+1\n",
    "df=pd.DataFrame(d, columns=('tfidf_tokens', 'tf-idf'))\n",
    "df.sort_values(by=['tf-idf'],ascending=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1446)\t0.43193348220168404\n",
      "  (0, 993)\t0.5726629431746175\n",
      "  (0, 278)\t0.5905272263925467\n",
      "  (0, 244)\t0.36982186976548354\n",
      "  (1, 1457)\t0.6494640308231909\n",
      "  (1, 750)\t0.44626073888543205\n",
      "  (1, 520)\t0.5024698527821166\n",
      "  (1, 233)\t0.35576940936713425\n",
      "  (2, 1165)\t0.4973506648696112\n",
      "  (2, 1163)\t0.4506148851099638\n",
      "  (2, 959)\t0.37378798426811904\n",
      "  (2, 717)\t0.3824072104070653\n",
      "  (2, 206)\t0.31704491476442354\n",
      "  (2, 80)\t0.40387910535031635\n",
      "  (3, 1417)\t0.6574013625789735\n",
      "  (3, 1045)\t0.5956257031390934\n",
      "  (3, 384)\t0.4615771552399117\n",
      "  (4, 1181)\t0.4272021044641115\n",
      "  (4, 567)\t0.5989051065676185\n",
      "  (4, 493)\t0.4025799688062384\n",
      "  (4, 179)\t0.544738840165296\n",
      "  (5, 1266)\t0.2419272974625589\n",
      "  (5, 950)\t0.5289820811452202\n",
      "  (5, 550)\t0.290502405770976\n",
      "  (5, 277)\t0.5014298393301082\n",
      "  :\t:\n",
      "  (2345, 1151)\t0.5479599649112801\n",
      "  (2345, 394)\t0.31890497346203267\n",
      "  (2345, 77)\t0.43460807005112356\n",
      "  (2346, 1450)\t0.3162015309808109\n",
      "  (2346, 1291)\t0.5282355349125356\n",
      "  (2346, 1266)\t0.22894517642333365\n",
      "  (2346, 867)\t0.455047743879343\n",
      "  (2346, 550)\t0.27491368373150216\n",
      "  (2346, 534)\t0.43275481507682917\n",
      "  (2346, 34)\t0.3140783420881838\n",
      "  (2347, 1181)\t0.27941385737751306\n",
      "  (2347, 1006)\t0.2876091988702871\n",
      "  (2347, 970)\t0.39171713875114345\n",
      "  (2347, 899)\t0.2723527965763989\n",
      "  (2347, 782)\t0.3061578161532973\n",
      "  (2347, 483)\t0.39171713875114345\n",
      "  (2347, 420)\t0.2898811918431667\n",
      "  (2347, 332)\t0.3562893979299781\n",
      "  (2347, 283)\t0.39171713875114345\n",
      "  (2348, 1580)\t0.6905808556784789\n",
      "  (2348, 947)\t0.5983337812028068\n",
      "  (2348, 59)\t0.4063185548826581\n",
      "  (2349, 811)\t0.31584953186991244\n",
      "  (2349, 628)\t0.5958551007729944\n",
      "  (2349, 446)\t0.7383737347037487\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1605, 1605)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(tfidfvectorizer.vocabulary_.keys())),len(set(list(tfidfvectorizer.vocabulary_.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train[1124,93]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['tfidf_tokens'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      False\n",
       "1      False\n",
       "2      False\n",
       "3      False\n",
       "4      False\n",
       "       ...  \n",
       "339     True\n",
       "340     True\n",
       "341     True\n",
       "342     True\n",
       "343    False\n",
       "Name: tfidf_tokens, Length: 344, dtype: bool"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tfidf_tokens'].duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf_tokens</th>\n",
       "      <th>tf-idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>laboratory</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>tetherless</td>\n",
       "      <td>0.776121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>research</td>\n",
       "      <td>0.744280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>lab</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>infrastructure</td>\n",
       "      <td>0.777126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>bioorganic</td>\n",
       "      <td>0.743031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>facility</td>\n",
       "      <td>0.768427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>lab</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>laboratory</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>laboratory</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>lab</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>diffractometer</td>\n",
       "      <td>0.769890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tfidf_tokens    tf-idf\n",
       "47       laboratory  1.000000\n",
       "91       tetherless  0.776121\n",
       "112        research  0.744280\n",
       "113             lab  1.000000\n",
       "185  infrastructure  0.777126\n",
       "213      bioorganic  0.743031\n",
       "217        facility  0.768427\n",
       "239             lab  1.000000\n",
       "263      laboratory  1.000000\n",
       "281      laboratory  1.000000\n",
       "341             lab  1.000000\n",
       "342  diffractometer  0.769890"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.duplicated(), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf_tokens</th>\n",
       "      <th>tf-idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>canadian</td>\n",
       "      <td>0.864165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>infrastructure</td>\n",
       "      <td>0.777126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>systems</td>\n",
       "      <td>0.695759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>design</td>\n",
       "      <td>0.659967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>smart</td>\n",
       "      <td>0.644996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>degeneration</td>\n",
       "      <td>0.643573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>resources</td>\n",
       "      <td>0.630851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>joint</td>\n",
       "      <td>0.585367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>nutrition</td>\n",
       "      <td>0.580851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>integrated</td>\n",
       "      <td>0.566357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>muscle</td>\n",
       "      <td>0.565977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>investigating</td>\n",
       "      <td>0.545913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>laboratory</td>\n",
       "      <td>0.543947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sensors</td>\n",
       "      <td>0.517979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>efficacy</td>\n",
       "      <td>0.516184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>determination</td>\n",
       "      <td>0.516184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wearable</td>\n",
       "      <td>0.509067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>musculoskeletal</td>\n",
       "      <td>0.507751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>innovation</td>\n",
       "      <td>0.506006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>laser</td>\n",
       "      <td>0.501726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tfidf_tokens    tf-idf\n",
       "19         canadian  0.864165\n",
       "17   infrastructure  0.777126\n",
       "18          systems  0.695759\n",
       "14           design  0.659967\n",
       "15            smart  0.644996\n",
       "8      degeneration  0.643573\n",
       "9         resources  0.630851\n",
       "7             joint  0.585367\n",
       "11        nutrition  0.580851\n",
       "13       integrated  0.566357\n",
       "2            muscle  0.565977\n",
       "12    investigating  0.545913\n",
       "16       laboratory  0.543947\n",
       "5           sensors  0.517979\n",
       "3          efficacy  0.516184\n",
       "4     determination  0.516184\n",
       "6          wearable  0.509067\n",
       "1   musculoskeletal  0.507751\n",
       "10       innovation  0.506006\n",
       "0             laser  0.501726"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract the words for with the tf-idf of higher than 0.5 for test set.\n",
    "m=0\n",
    "d=[]\n",
    "for col in tfidf_test.nonzero()[1]:\n",
    "    if tfidf_test[tfidf_train.nonzero()[0][m],col] > 0.5:\n",
    "        #print (words[col], '-', tfidf_test[tfidf_train.nonzero()[0][m],col])\n",
    "        d.append((tfidf_tokens[col],tfidf_test[tfidf_train.nonzero()[0][m],col]))\n",
    "        m=m+1\n",
    "    else:\n",
    "        m=m+1\n",
    "df=pd.DataFrame(d, columns=('tfidf_tokens', 'tf-idf'))\n",
    "df.sort_values(by=['tf-idf'],ascending=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Make word2vec for training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " here I tokenized the words in project title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2350, 784)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train),len(x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train=x_train.apply(gensim.utils.simple_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test=x_test.apply(gensim.utils.simple_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['system',\n",
       " 'for',\n",
       " 'flame',\n",
       " 'synthesis',\n",
       " 'collection',\n",
       " 'and',\n",
       " 'of',\n",
       " 'customized',\n",
       " 'nanoparticles']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train[2855]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the word2vec model \n",
    "train the model for project title using window size of 3 i.e. 3 words before the present word and 3 words ahead. A sentence with at least 2 words should be considered, configure this using min_count parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_word2vec = gensim.models.Word2Vec(\n",
    "    window=10,\n",
    "    min_count=2,\n",
    "    workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_word2vec.build_vocab(text_train, progress_per=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63594, 102410)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_word2vec.train(text_train, total_examples=model_word2vec.corpus_count,epochs=model_word2vec.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20260, 35980)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_word2vec.train(text_test, total_examples=model_word2vec.corpus_count,epochs=model_word2vec.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_word2vec.wv['density']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_word2vec.wv.index_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set(model_word2vec.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Atieh\\AppData\\Local\\Temp\\ipykernel_3252\\2701933075.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_vect_train = np.array([np.array([model_word2vec.wv[i] for i in ls if i in words])for ls in text_train])\n"
     ]
    }
   ],
   "source": [
    "x_vect_train = np.array([np.array([model_word2vec.wv[i] for i in ls if i in words])for ls in text_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Atieh\\AppData\\Local\\Temp\\ipykernel_3252\\754669392.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_vect_test = np.array([np.array([model_word2vec.wv[i] for i in ls if i in words])for ls in text_test])\n"
     ]
    }
   ],
   "source": [
    "x_vect_test = np.array([np.array([model_word2vec.wv[i] for i in ls if i in words])for ls in text_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2350, 2350)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_vect_train),len(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 784)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_vect_test),len(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2855    [system, for, flame, synthesis, collection, an...\n",
       "Name: project_title, dtype: object"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_word2vec.wv['system'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.00871122e-01,  1.73023179e-01,  1.47775054e-01,  2.51696944e-01,\n",
       "       -1.70583092e-02, -6.94829524e-01,  3.00379634e-01,  1.14963222e+00,\n",
       "       -4.82180834e-01, -1.78977177e-01, -2.37332582e-01, -7.52155721e-01,\n",
       "       -1.30390614e-01,  3.31210703e-01,  1.74497798e-01, -4.13159251e-01,\n",
       "        2.78974295e-01, -2.85834908e-01, -1.39389336e-01, -1.09359241e+00,\n",
       "        2.75877833e-01,  7.88470730e-02,  3.41476738e-01, -2.83396482e-01,\n",
       "       -6.22756444e-02, -2.32620090e-01, -2.79178083e-01, -3.45266759e-01,\n",
       "       -5.38915634e-01,  1.92605391e-01,  6.19558215e-01, -3.19730416e-02,\n",
       "        2.60848198e-02, -5.18770754e-01, -9.65503529e-02,  4.46985871e-01,\n",
       "        7.18843564e-02, -4.80641693e-01, -3.45022947e-01, -6.55369699e-01,\n",
       "       -6.77752346e-02, -3.81142855e-01, -3.80810112e-01,  8.47513005e-02,\n",
       "        5.26263535e-01, -5.02047502e-02, -3.03748488e-01, -1.14405632e-01,\n",
       "        3.21249783e-01,  3.56290370e-01,  3.06225806e-01, -3.26238871e-01,\n",
       "       -4.45843816e-01, -1.96063804e-04, -5.62065184e-01,  2.47585118e-01,\n",
       "        1.44520387e-01, -1.64176390e-01, -7.70271420e-01,  1.56569496e-01,\n",
       "        9.51674208e-02,  1.91058576e-01, -6.68774173e-02, -1.06816635e-01,\n",
       "       -6.29305243e-01,  4.82854813e-01,  4.70792390e-02,  5.28609455e-01,\n",
       "       -6.64295614e-01,  5.35203278e-01, -1.72253400e-01,  4.01920229e-01,\n",
       "        6.29307091e-01, -6.30296320e-02,  4.76989418e-01,  1.02066949e-01,\n",
       "       -4.39887531e-02, -1.87308993e-02, -2.55217403e-01,  1.42212242e-01,\n",
       "       -2.67292738e-01, -2.24225238e-01, -3.52330357e-01,  4.85182017e-01,\n",
       "       -1.11454591e-01, -1.60739347e-01,  1.63165957e-01,  2.90391713e-01,\n",
       "        6.17794693e-01,  2.43050888e-01,  4.24108982e-01,  2.25424901e-01,\n",
       "        7.50929564e-02,  1.28228337e-01,  1.06266630e+00,  5.46817780e-01,\n",
       "        3.55274081e-01, -6.30164444e-01,  1.97039589e-01, -2.14050964e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_word2vec.wv['system']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.50106996,  0.170521  ,  0.14840825,  0.25503615, -0.01838474,\n",
       "       -0.7161172 ,  0.2941861 ,  1.1733781 , -0.48451492, -0.176689  ,\n",
       "       -0.2265364 , -0.77177584, -0.13234998,  0.32857287,  0.17303833,\n",
       "       -0.41979924,  0.2897585 , -0.288707  , -0.15131928, -1.101101  ,\n",
       "        0.28639168,  0.08603162,  0.3393642 , -0.29755768, -0.0592332 ,\n",
       "       -0.24140081, -0.28173792, -0.35400632, -0.55379397,  0.17871608,\n",
       "        0.63080454, -0.01291794,  0.04991139, -0.50816035, -0.1158812 ,\n",
       "        0.45163038,  0.07725848, -0.49619344, -0.34481487, -0.65193975,\n",
       "       -0.07852737, -0.36794248, -0.37712902,  0.07744592,  0.5338279 ,\n",
       "       -0.04491355, -0.2989662 , -0.11243424,  0.31621563,  0.37753013,\n",
       "        0.30814514, -0.32163897, -0.43431166,  0.0057396 , -0.55477977,\n",
       "        0.23959506,  0.1555364 , -0.15906878, -0.7748894 ,  0.16154905,\n",
       "        0.078765  ,  0.19961523, -0.07401608, -0.1244307 , -0.64145267,\n",
       "        0.47409683,  0.0416306 ,  0.5172847 , -0.6787816 ,  0.5281582 ,\n",
       "       -0.18759358,  0.3940787 ,  0.6229286 , -0.06567884,  0.46902382,\n",
       "        0.08967169, -0.03450196, -0.03877718, -0.25057417,  0.14510277,\n",
       "       -0.2509037 , -0.23585673, -0.350512  ,  0.494343  , -0.1174433 ,\n",
       "       -0.1599436 ,  0.14486888,  0.29813737,  0.6248502 ,  0.2579777 ,\n",
       "        0.44111234,  0.22740793,  0.07938789,  0.14163966,  1.0773025 ,\n",
       "        0.5514445 ,  0.34769648, -0.63216186,  0.20014755, -0.21534152],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vect_train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute sentence vectors by averaging the word vectors for the words contained in the sentence\n",
    "x_vect_avg_train = []\n",
    "for v in x_vect_train:\n",
    "    if v.size:\n",
    "        x_vect_avg_train.append(v.mean(axis=0))\n",
    "    else:\n",
    "        x_vect_avg_train.append(np.zeros(100, dtype=float))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute sentence vectors by averaging the word vectors for the words contained in the sentence\n",
    "x_vect_avg_test = []\n",
    "for v in x_vect_test:\n",
    "    if v.size:\n",
    "        x_vect_avg_test.append(v.mean(axis=0))\n",
    "    else:\n",
    "        x_vect_avg_test.append(np.zeros(100, dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2350, 784)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vect_train.size,x_vect_test.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109 100\n",
      "98 100\n",
      "30 100\n",
      "30 100\n",
      "145 100\n",
      "193 100\n",
      "57 100\n",
      "36 100\n",
      "31 100\n",
      "68 100\n",
      "67 100\n",
      "86 100\n",
      "49 100\n",
      "47 100\n",
      "49 100\n",
      "98 100\n",
      "90 100\n",
      "186 100\n",
      "76 100\n",
      "97 100\n",
      "125 100\n",
      "75 100\n",
      "50 100\n",
      "50 100\n",
      "75 100\n",
      "62 100\n",
      "43 100\n",
      "107 100\n",
      "29 100\n",
      "42 100\n",
      "71 100\n",
      "80 100\n",
      "120 100\n",
      "56 100\n",
      "67 100\n",
      "31 100\n",
      "95 100\n",
      "63 100\n",
      "64 100\n",
      "79 100\n",
      "40 100\n",
      "78 100\n",
      "72 100\n",
      "44 100\n",
      "72 100\n",
      "69 100\n",
      "125 100\n",
      "97 100\n",
      "35 100\n",
      "40 100\n",
      "22 100\n",
      "84 100\n",
      "106 100\n",
      "74 100\n",
      "60 100\n",
      "40 100\n",
      "89 100\n",
      "81 100\n",
      "64 100\n",
      "40 100\n",
      "62 100\n",
      "64 100\n",
      "77 100\n",
      "73 100\n",
      "74 100\n",
      "144 100\n",
      "97 100\n",
      "118 100\n",
      "70 100\n",
      "77 100\n",
      "127 100\n",
      "130 100\n",
      "74 100\n",
      "106 100\n",
      "59 100\n",
      "46 100\n",
      "123 100\n",
      "88 100\n",
      "80 100\n",
      "72 100\n",
      "120 100\n",
      "43 100\n",
      "70 100\n",
      "60 100\n",
      "58 100\n",
      "78 100\n",
      "150 100\n",
      "41 100\n",
      "83 100\n",
      "27 100\n",
      "30 100\n",
      "52 100\n",
      "67 100\n",
      "71 100\n",
      "46 100\n",
      "112 100\n",
      "68 100\n",
      "73 100\n",
      "52 100\n",
      "88 100\n",
      "88 100\n",
      "23 100\n",
      "102 100\n",
      "44 100\n",
      "86 100\n",
      "31 100\n",
      "84 100\n",
      "34 100\n",
      "61 100\n",
      "46 100\n",
      "72 100\n",
      "90 100\n",
      "50 100\n",
      "53 100\n",
      "111 100\n",
      "88 100\n",
      "45 100\n",
      "31 100\n",
      "100 100\n",
      "108 100\n",
      "50 100\n",
      "78 100\n",
      "52 100\n",
      "59 100\n",
      "40 100\n",
      "55 100\n",
      "59 100\n",
      "42 100\n",
      "195 100\n",
      "52 100\n",
      "72 100\n",
      "63 100\n",
      "66 100\n",
      "94 100\n",
      "63 100\n",
      "28 100\n",
      "113 100\n",
      "116 100\n",
      "128 100\n",
      "47 100\n",
      "43 100\n",
      "112 100\n",
      "82 100\n",
      "113 100\n",
      "74 100\n",
      "126 100\n",
      "128 100\n",
      "49 100\n",
      "37 100\n",
      "98 100\n",
      "74 100\n",
      "121 100\n",
      "56 100\n",
      "142 100\n",
      "47 100\n",
      "55 100\n",
      "81 100\n",
      "44 100\n",
      "92 100\n",
      "76 100\n",
      "57 100\n",
      "128 100\n",
      "123 100\n",
      "54 100\n",
      "40 100\n",
      "77 100\n",
      "99 100\n",
      "56 100\n",
      "52 100\n",
      "66 100\n",
      "90 100\n",
      "51 100\n",
      "57 100\n",
      "82 100\n",
      "67 100\n",
      "89 100\n",
      "39 100\n",
      "52 100\n",
      "86 100\n",
      "38 100\n",
      "39 100\n",
      "119 100\n",
      "138 100\n",
      "28 100\n",
      "121 100\n",
      "114 100\n",
      "63 100\n",
      "11 100\n",
      "21 100\n",
      "63 100\n",
      "75 100\n",
      "106 100\n",
      "53 100\n",
      "50 100\n",
      "70 100\n",
      "161 100\n",
      "60 100\n",
      "43 100\n",
      "89 100\n",
      "98 100\n",
      "94 100\n",
      "49 100\n",
      "27 100\n",
      "99 100\n",
      "48 100\n",
      "62 100\n",
      "89 100\n",
      "56 100\n",
      "142 100\n",
      "148 100\n",
      "127 100\n",
      "70 100\n",
      "68 100\n",
      "54 100\n",
      "63 100\n",
      "156 100\n",
      "88 100\n",
      "82 100\n",
      "64 100\n",
      "66 100\n",
      "144 100\n",
      "132 100\n",
      "72 100\n",
      "183 100\n",
      "35 100\n",
      "39 100\n",
      "63 100\n",
      "111 100\n",
      "21 100\n",
      "40 100\n",
      "95 100\n",
      "78 100\n",
      "76 100\n",
      "167 100\n",
      "98 100\n",
      "61 100\n",
      "29 100\n",
      "35 100\n",
      "75 100\n",
      "49 100\n",
      "67 100\n",
      "87 100\n",
      "79 100\n",
      "42 100\n",
      "44 100\n",
      "29 100\n",
      "64 100\n",
      "103 100\n",
      "39 100\n",
      "84 100\n",
      "39 100\n",
      "63 100\n",
      "25 100\n",
      "57 100\n",
      "49 100\n",
      "65 100\n",
      "112 100\n",
      "70 100\n",
      "68 100\n",
      "35 100\n",
      "49 100\n",
      "126 100\n",
      "109 100\n",
      "138 100\n",
      "30 100\n",
      "31 100\n",
      "64 100\n",
      "36 100\n",
      "142 100\n",
      "82 100\n",
      "41 100\n",
      "81 100\n",
      "49 100\n",
      "113 100\n",
      "47 100\n",
      "57 100\n",
      "94 100\n",
      "40 100\n",
      "57 100\n",
      "93 100\n",
      "65 100\n",
      "49 100\n",
      "126 100\n",
      "91 100\n",
      "48 100\n",
      "37 100\n",
      "46 100\n",
      "60 100\n",
      "36 100\n",
      "130 100\n",
      "51 100\n",
      "86 100\n",
      "151 100\n",
      "154 100\n",
      "171 100\n",
      "49 100\n",
      "90 100\n",
      "61 100\n",
      "42 100\n",
      "26 100\n",
      "80 100\n",
      "51 100\n",
      "46 100\n",
      "65 100\n",
      "104 100\n",
      "69 100\n",
      "96 100\n",
      "91 100\n",
      "52 100\n",
      "165 100\n",
      "146 100\n",
      "92 100\n",
      "55 100\n",
      "18 100\n",
      "43 100\n",
      "52 100\n",
      "79 100\n",
      "28 100\n",
      "154 100\n",
      "52 100\n",
      "96 100\n",
      "68 100\n",
      "76 100\n",
      "69 100\n",
      "72 100\n",
      "72 100\n",
      "117 100\n",
      "74 100\n",
      "98 100\n",
      "68 100\n",
      "60 100\n",
      "94 100\n",
      "93 100\n",
      "69 100\n",
      "135 100\n",
      "92 100\n",
      "86 100\n",
      "81 100\n",
      "93 100\n",
      "76 100\n",
      "47 100\n",
      "50 100\n",
      "65 100\n",
      "93 100\n",
      "97 100\n",
      "56 100\n",
      "137 100\n",
      "123 100\n",
      "45 100\n",
      "33 100\n",
      "55 100\n",
      "38 100\n",
      "115 100\n",
      "46 100\n",
      "81 100\n",
      "48 100\n",
      "47 100\n",
      "92 100\n",
      "66 100\n",
      "93 100\n",
      "46 100\n",
      "50 100\n",
      "79 100\n",
      "41 100\n",
      "41 100\n",
      "81 100\n",
      "56 100\n",
      "69 100\n",
      "31 100\n",
      "179 100\n",
      "133 100\n",
      "114 100\n",
      "44 100\n",
      "67 100\n",
      "104 100\n",
      "70 100\n",
      "33 100\n",
      "84 100\n",
      "124 100\n",
      "59 100\n",
      "70 100\n",
      "116 100\n",
      "96 100\n",
      "58 100\n",
      "35 100\n",
      "100 100\n",
      "74 100\n",
      "60 100\n",
      "57 100\n",
      "60 100\n",
      "18 100\n",
      "40 100\n",
      "108 100\n",
      "101 100\n",
      "51 100\n",
      "57 100\n",
      "43 100\n",
      "28 100\n",
      "24 100\n",
      "85 100\n",
      "138 100\n",
      "93 100\n",
      "67 100\n",
      "170 100\n",
      "156 100\n",
      "98 100\n",
      "74 100\n",
      "30 100\n",
      "150 100\n",
      "50 100\n",
      "97 100\n",
      "179 100\n",
      "93 100\n",
      "48 100\n",
      "112 100\n",
      "89 100\n",
      "50 100\n",
      "52 100\n",
      "41 100\n",
      "52 100\n",
      "84 100\n",
      "30 100\n",
      "99 100\n",
      "136 100\n",
      "66 100\n",
      "75 100\n",
      "87 100\n",
      "76 100\n",
      "48 100\n",
      "43 100\n",
      "88 100\n",
      "87 100\n",
      "94 100\n",
      "175 100\n",
      "82 100\n",
      "160 100\n",
      "50 100\n",
      "80 100\n",
      "81 100\n",
      "79 100\n",
      "126 100\n",
      "52 100\n",
      "87 100\n",
      "152 100\n",
      "106 100\n",
      "70 100\n",
      "44 100\n",
      "70 100\n",
      "112 100\n",
      "109 100\n",
      "59 100\n",
      "81 100\n",
      "45 100\n",
      "43 100\n",
      "60 100\n",
      "48 100\n",
      "58 100\n",
      "66 100\n",
      "92 100\n",
      "43 100\n",
      "74 100\n",
      "57 100\n",
      "79 100\n",
      "140 100\n",
      "95 100\n",
      "99 100\n",
      "51 100\n",
      "65 100\n",
      "27 100\n",
      "92 100\n",
      "56 100\n",
      "90 100\n",
      "80 100\n",
      "138 100\n",
      "85 100\n",
      "159 100\n",
      "78 100\n",
      "64 100\n",
      "83 100\n",
      "62 100\n",
      "32 100\n",
      "72 100\n",
      "47 100\n",
      "48 100\n",
      "73 100\n",
      "35 100\n",
      "101 100\n",
      "96 100\n",
      "47 100\n",
      "53 100\n",
      "100 100\n",
      "47 100\n",
      "63 100\n",
      "49 100\n",
      "93 100\n",
      "138 100\n",
      "149 100\n",
      "72 100\n",
      "111 100\n",
      "88 100\n",
      "39 100\n",
      "144 100\n",
      "24 100\n",
      "68 100\n",
      "34 100\n",
      "44 100\n",
      "39 100\n",
      "16 100\n",
      "104 100\n",
      "83 100\n",
      "51 100\n",
      "60 100\n",
      "68 100\n",
      "96 100\n",
      "71 100\n",
      "67 100\n",
      "142 100\n",
      "117 100\n",
      "55 100\n",
      "78 100\n",
      "59 100\n",
      "76 100\n",
      "97 100\n",
      "50 100\n",
      "61 100\n",
      "102 100\n",
      "147 100\n",
      "62 100\n",
      "90 100\n",
      "63 100\n",
      "66 100\n",
      "65 100\n",
      "76 100\n",
      "82 100\n",
      "174 100\n",
      "46 100\n",
      "95 100\n",
      "110 100\n",
      "114 100\n",
      "52 100\n",
      "32 100\n",
      "54 100\n",
      "86 100\n",
      "32 100\n",
      "84 100\n",
      "202 100\n",
      "52 100\n",
      "42 100\n",
      "86 100\n",
      "76 100\n",
      "92 100\n",
      "83 100\n",
      "78 100\n",
      "68 100\n",
      "65 100\n",
      "53 100\n",
      "29 100\n",
      "130 100\n",
      "44 100\n",
      "62 100\n",
      "67 100\n",
      "29 100\n",
      "33 100\n",
      "36 100\n",
      "66 100\n",
      "91 100\n",
      "86 100\n",
      "73 100\n",
      "179 100\n",
      "74 100\n",
      "84 100\n",
      "118 100\n",
      "39 100\n",
      "104 100\n",
      "51 100\n",
      "23 100\n",
      "68 100\n",
      "82 100\n",
      "44 100\n",
      "132 100\n",
      "79 100\n",
      "30 100\n",
      "35 100\n",
      "106 100\n",
      "29 100\n",
      "63 100\n",
      "117 100\n",
      "68 100\n",
      "103 100\n",
      "56 100\n",
      "48 100\n",
      "37 100\n",
      "52 100\n",
      "38 100\n",
      "120 100\n",
      "143 100\n",
      "80 100\n",
      "84 100\n",
      "127 100\n",
      "41 100\n",
      "36 100\n",
      "93 100\n",
      "53 100\n",
      "106 100\n",
      "117 100\n",
      "94 100\n",
      "76 100\n",
      "94 100\n",
      "50 100\n",
      "75 100\n",
      "84 100\n",
      "38 100\n",
      "71 100\n",
      "32 100\n",
      "70 100\n",
      "50 100\n",
      "51 100\n",
      "72 100\n",
      "35 100\n",
      "29 100\n",
      "59 100\n",
      "28 100\n",
      "64 100\n",
      "109 100\n",
      "100 100\n",
      "38 100\n",
      "119 100\n",
      "179 100\n",
      "72 100\n",
      "117 100\n",
      "37 100\n",
      "96 100\n",
      "50 100\n",
      "119 100\n",
      "121 100\n",
      "58 100\n",
      "59 100\n",
      "29 100\n",
      "55 100\n",
      "147 100\n",
      "58 100\n",
      "105 100\n",
      "53 100\n",
      "67 100\n",
      "61 100\n",
      "99 100\n",
      "37 100\n",
      "110 100\n",
      "91 100\n",
      "73 100\n",
      "72 100\n",
      "75 100\n",
      "24 100\n",
      "119 100\n",
      "71 100\n",
      "72 100\n",
      "97 100\n",
      "94 100\n",
      "35 100\n",
      "67 100\n",
      "129 100\n",
      "73 100\n",
      "68 100\n",
      "48 100\n",
      "27 100\n",
      "72 100\n",
      "109 100\n",
      "66 100\n",
      "58 100\n",
      "98 100\n",
      "49 100\n",
      "93 100\n",
      "69 100\n",
      "132 100\n",
      "72 100\n",
      "30 100\n",
      "107 100\n",
      "48 100\n",
      "40 100\n",
      "121 100\n",
      "27 100\n",
      "36 100\n",
      "59 100\n",
      "85 100\n",
      "65 100\n",
      "95 100\n",
      "55 100\n",
      "65 100\n",
      "104 100\n",
      "67 100\n",
      "85 100\n",
      "79 100\n",
      "61 100\n",
      "72 100\n",
      "45 100\n",
      "123 100\n",
      "91 100\n",
      "93 100\n",
      "63 100\n",
      "72 100\n",
      "68 100\n",
      "84 100\n",
      "110 100\n",
      "90 100\n",
      "44 100\n",
      "94 100\n",
      "32 100\n",
      "115 100\n",
      "52 100\n",
      "52 100\n",
      "60 100\n",
      "32 100\n",
      "55 100\n",
      "76 100\n",
      "97 100\n",
      "57 100\n",
      "83 100\n",
      "51 100\n",
      "74 100\n",
      "28 100\n",
      "25 100\n",
      "56 100\n",
      "81 100\n",
      "92 100\n",
      "97 100\n",
      "17 100\n",
      "55 100\n",
      "52 100\n",
      "66 100\n",
      "127 100\n",
      "49 100\n",
      "128 100\n",
      "41 100\n",
      "49 100\n",
      "54 100\n",
      "94 100\n",
      "74 100\n",
      "69 100\n",
      "62 100\n",
      "80 100\n",
      "99 100\n",
      "75 100\n",
      "53 100\n",
      "82 100\n",
      "122 100\n",
      "95 100\n",
      "45 100\n",
      "56 100\n",
      "57 100\n",
      "134 100\n",
      "74 100\n",
      "50 100\n",
      "52 100\n",
      "53 100\n",
      "114 100\n",
      "31 100\n",
      "85 100\n",
      "74 100\n",
      "56 100\n",
      "65 100\n",
      "37 100\n",
      "75 100\n",
      "42 100\n",
      "76 100\n",
      "60 100\n",
      "133 100\n",
      "55 100\n",
      "85 100\n",
      "35 100\n",
      "92 100\n",
      "64 100\n",
      "66 100\n",
      "65 100\n",
      "65 100\n",
      "72 100\n",
      "101 100\n",
      "34 100\n",
      "54 100\n",
      "80 100\n",
      "41 100\n",
      "59 100\n",
      "97 100\n",
      "142 100\n",
      "69 100\n",
      "80 100\n",
      "49 100\n",
      "80 100\n",
      "163 100\n",
      "91 100\n",
      "21 100\n",
      "93 100\n",
      "47 100\n",
      "54 100\n",
      "76 100\n",
      "61 100\n",
      "148 100\n",
      "143 100\n",
      "38 100\n",
      "102 100\n",
      "28 100\n",
      "163 100\n",
      "39 100\n",
      "45 100\n",
      "59 100\n",
      "55 100\n",
      "62 100\n",
      "41 100\n",
      "120 100\n",
      "57 100\n",
      "74 100\n",
      "89 100\n",
      "74 100\n",
      "36 100\n",
      "79 100\n",
      "57 100\n",
      "25 100\n",
      "85 100\n",
      "95 100\n",
      "76 100\n",
      "81 100\n",
      "107 100\n",
      "63 100\n",
      "67 100\n",
      "82 100\n",
      "34 100\n",
      "63 100\n",
      "144 100\n",
      "67 100\n",
      "125 100\n",
      "46 100\n",
      "65 100\n",
      "57 100\n",
      "44 100\n",
      "59 100\n",
      "61 100\n",
      "59 100\n",
      "51 100\n",
      "130 100\n",
      "38 100\n",
      "45 100\n",
      "40 100\n",
      "136 100\n",
      "127 100\n",
      "20 100\n",
      "39 100\n",
      "72 100\n",
      "171 100\n",
      "47 100\n",
      "75 100\n",
      "41 100\n",
      "23 100\n",
      "38 100\n",
      "67 100\n",
      "44 100\n",
      "134 100\n",
      "114 100\n",
      "146 100\n",
      "49 100\n",
      "77 100\n",
      "83 100\n",
      "34 100\n",
      "41 100\n",
      "104 100\n",
      "68 100\n",
      "63 100\n",
      "57 100\n",
      "45 100\n",
      "69 100\n",
      "66 100\n",
      "108 100\n",
      "95 100\n",
      "50 100\n",
      "35 100\n",
      "95 100\n",
      "37 100\n",
      "94 100\n",
      "79 100\n",
      "34 100\n",
      "36 100\n",
      "49 100\n",
      "90 100\n",
      "72 100\n",
      "67 100\n",
      "89 100\n",
      "73 100\n",
      "118 100\n",
      "134 100\n",
      "67 100\n",
      "52 100\n",
      "29 100\n",
      "78 100\n",
      "46 100\n",
      "72 100\n",
      "57 100\n",
      "76 100\n",
      "29 100\n",
      "59 100\n",
      "38 100\n",
      "35 100\n",
      "48 100\n",
      "154 100\n",
      "37 100\n",
      "45 100\n",
      "56 100\n",
      "52 100\n",
      "42 100\n",
      "51 100\n",
      "108 100\n",
      "25 100\n",
      "55 100\n",
      "96 100\n",
      "36 100\n",
      "45 100\n",
      "87 100\n",
      "58 100\n",
      "143 100\n",
      "48 100\n",
      "30 100\n",
      "101 100\n",
      "33 100\n",
      "34 100\n",
      "85 100\n",
      "43 100\n",
      "42 100\n",
      "98 100\n",
      "32 100\n",
      "145 100\n",
      "99 100\n",
      "148 100\n",
      "58 100\n",
      "33 100\n",
      "89 100\n",
      "76 100\n",
      "63 100\n",
      "90 100\n",
      "126 100\n",
      "83 100\n",
      "80 100\n",
      "94 100\n",
      "81 100\n",
      "38 100\n",
      "71 100\n",
      "70 100\n",
      "69 100\n",
      "55 100\n",
      "75 100\n",
      "106 100\n",
      "117 100\n",
      "33 100\n",
      "67 100\n",
      "81 100\n",
      "78 100\n",
      "45 100\n",
      "47 100\n",
      "71 100\n",
      "40 100\n",
      "101 100\n",
      "71 100\n",
      "38 100\n",
      "43 100\n",
      "108 100\n",
      "105 100\n",
      "77 100\n",
      "80 100\n",
      "61 100\n",
      "66 100\n",
      "33 100\n",
      "105 100\n",
      "54 100\n",
      "50 100\n",
      "32 100\n",
      "62 100\n",
      "92 100\n",
      "85 100\n",
      "80 100\n",
      "60 100\n",
      "81 100\n",
      "33 100\n",
      "49 100\n",
      "78 100\n",
      "40 100\n",
      "114 100\n",
      "116 100\n",
      "46 100\n",
      "93 100\n",
      "63 100\n",
      "65 100\n",
      "82 100\n",
      "89 100\n",
      "87 100\n",
      "95 100\n",
      "50 100\n",
      "94 100\n",
      "109 100\n",
      "56 100\n",
      "47 100\n",
      "50 100\n",
      "53 100\n",
      "87 100\n",
      "82 100\n",
      "56 100\n",
      "62 100\n",
      "61 100\n",
      "65 100\n",
      "58 100\n",
      "56 100\n",
      "101 100\n",
      "34 100\n",
      "65 100\n",
      "85 100\n",
      "57 100\n",
      "101 100\n",
      "74 100\n",
      "25 100\n",
      "41 100\n",
      "38 100\n",
      "101 100\n",
      "87 100\n",
      "64 100\n",
      "43 100\n",
      "82 100\n",
      "62 100\n",
      "56 100\n",
      "59 100\n",
      "111 100\n",
      "54 100\n",
      "75 100\n",
      "77 100\n",
      "103 100\n",
      "104 100\n",
      "33 100\n",
      "95 100\n",
      "59 100\n",
      "89 100\n",
      "62 100\n",
      "63 100\n",
      "64 100\n",
      "45 100\n",
      "73 100\n",
      "145 100\n",
      "51 100\n",
      "109 100\n",
      "40 100\n",
      "85 100\n",
      "95 100\n",
      "38 100\n",
      "47 100\n",
      "73 100\n",
      "129 100\n",
      "107 100\n",
      "27 100\n",
      "60 100\n",
      "67 100\n",
      "113 100\n",
      "38 100\n",
      "147 100\n",
      "45 100\n",
      "103 100\n",
      "120 100\n",
      "23 100\n",
      "39 100\n",
      "35 100\n",
      "94 100\n",
      "30 100\n",
      "118 100\n",
      "37 100\n",
      "39 100\n",
      "55 100\n",
      "37 100\n",
      "150 100\n",
      "79 100\n",
      "45 100\n",
      "116 100\n",
      "42 100\n",
      "39 100\n",
      "32 100\n",
      "113 100\n",
      "37 100\n",
      "123 100\n",
      "98 100\n",
      "71 100\n",
      "85 100\n",
      "48 100\n",
      "39 100\n",
      "126 100\n",
      "48 100\n",
      "79 100\n",
      "48 100\n",
      "118 100\n",
      "44 100\n",
      "41 100\n",
      "155 100\n",
      "91 100\n",
      "44 100\n",
      "100 100\n",
      "73 100\n",
      "63 100\n",
      "74 100\n",
      "72 100\n",
      "48 100\n",
      "181 100\n",
      "56 100\n",
      "34 100\n",
      "73 100\n",
      "151 100\n",
      "60 100\n",
      "54 100\n",
      "35 100\n",
      "85 100\n",
      "57 100\n",
      "149 100\n",
      "48 100\n",
      "95 100\n",
      "61 100\n",
      "108 100\n",
      "59 100\n",
      "99 100\n",
      "44 100\n",
      "64 100\n",
      "54 100\n",
      "122 100\n",
      "21 100\n",
      "51 100\n",
      "54 100\n",
      "47 100\n",
      "53 100\n",
      "69 100\n",
      "27 100\n",
      "42 100\n",
      "78 100\n",
      "142 100\n",
      "89 100\n",
      "84 100\n",
      "30 100\n",
      "100 100\n",
      "144 100\n",
      "82 100\n",
      "86 100\n",
      "131 100\n",
      "113 100\n",
      "104 100\n",
      "88 100\n",
      "92 100\n",
      "71 100\n",
      "36 100\n",
      "29 100\n",
      "70 100\n",
      "66 100\n",
      "60 100\n",
      "73 100\n",
      "57 100\n",
      "45 100\n",
      "71 100\n",
      "91 100\n",
      "65 100\n",
      "73 100\n",
      "113 100\n",
      "145 100\n",
      "58 100\n",
      "137 100\n",
      "56 100\n",
      "66 100\n",
      "40 100\n",
      "99 100\n",
      "52 100\n",
      "42 100\n",
      "79 100\n",
      "69 100\n",
      "70 100\n",
      "144 100\n",
      "58 100\n",
      "43 100\n",
      "35 100\n",
      "117 100\n",
      "57 100\n",
      "147 100\n",
      "47 100\n",
      "34 100\n",
      "36 100\n",
      "39 100\n",
      "132 100\n",
      "68 100\n",
      "123 100\n",
      "72 100\n",
      "45 100\n",
      "65 100\n",
      "45 100\n",
      "79 100\n",
      "42 100\n",
      "63 100\n",
      "83 100\n",
      "63 100\n",
      "74 100\n",
      "128 100\n",
      "117 100\n",
      "126 100\n",
      "43 100\n",
      "125 100\n",
      "108 100\n",
      "156 100\n",
      "64 100\n",
      "77 100\n",
      "65 100\n",
      "65 100\n",
      "58 100\n",
      "33 100\n",
      "93 100\n",
      "146 100\n",
      "158 100\n",
      "66 100\n",
      "69 100\n",
      "67 100\n",
      "88 100\n",
      "115 100\n",
      "80 100\n",
      "43 100\n",
      "47 100\n",
      "82 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 100\n",
      "29 100\n",
      "64 100\n",
      "52 100\n",
      "60 100\n",
      "55 100\n",
      "34 100\n",
      "79 100\n",
      "64 100\n",
      "83 100\n",
      "40 100\n",
      "121 100\n",
      "55 100\n",
      "88 100\n",
      "116 100\n",
      "91 100\n",
      "50 100\n",
      "48 100\n",
      "47 100\n",
      "56 100\n",
      "94 100\n",
      "90 100\n",
      "78 100\n",
      "106 100\n",
      "70 100\n",
      "40 100\n",
      "142 100\n",
      "54 100\n",
      "58 100\n",
      "31 100\n",
      "65 100\n",
      "98 100\n",
      "93 100\n",
      "44 100\n",
      "82 100\n",
      "100 100\n",
      "49 100\n",
      "24 100\n",
      "50 100\n",
      "89 100\n",
      "150 100\n",
      "128 100\n",
      "42 100\n",
      "67 100\n",
      "70 100\n",
      "45 100\n",
      "119 100\n",
      "45 100\n",
      "34 100\n",
      "80 100\n",
      "117 100\n",
      "58 100\n",
      "49 100\n",
      "147 100\n",
      "94 100\n",
      "50 100\n",
      "58 100\n",
      "137 100\n",
      "40 100\n",
      "69 100\n",
      "74 100\n",
      "40 100\n",
      "53 100\n",
      "107 100\n",
      "86 100\n",
      "52 100\n",
      "29 100\n",
      "31 100\n",
      "123 100\n",
      "55 100\n",
      "138 100\n",
      "33 100\n",
      "101 100\n",
      "31 100\n",
      "144 100\n",
      "91 100\n",
      "31 100\n",
      "63 100\n",
      "38 100\n",
      "74 100\n",
      "67 100\n",
      "60 100\n",
      "83 100\n",
      "18 100\n",
      "48 100\n",
      "121 100\n",
      "43 100\n",
      "113 100\n",
      "71 100\n",
      "44 100\n",
      "101 100\n",
      "97 100\n",
      "85 100\n",
      "122 100\n",
      "59 100\n",
      "75 100\n",
      "23 100\n",
      "77 100\n",
      "29 100\n",
      "92 100\n",
      "82 100\n",
      "47 100\n",
      "56 100\n",
      "56 100\n",
      "60 100\n",
      "48 100\n",
      "69 100\n",
      "57 100\n",
      "83 100\n",
      "67 100\n",
      "49 100\n",
      "50 100\n",
      "107 100\n",
      "81 100\n",
      "36 100\n",
      "60 100\n",
      "104 100\n",
      "70 100\n",
      "88 100\n",
      "50 100\n",
      "62 100\n",
      "101 100\n",
      "48 100\n",
      "101 100\n",
      "75 100\n",
      "48 100\n",
      "42 100\n",
      "39 100\n",
      "94 100\n",
      "102 100\n",
      "65 100\n",
      "64 100\n",
      "89 100\n",
      "100 100\n",
      "47 100\n",
      "82 100\n",
      "72 100\n",
      "88 100\n",
      "115 100\n",
      "68 100\n",
      "128 100\n",
      "41 100\n",
      "62 100\n",
      "47 100\n",
      "60 100\n",
      "81 100\n",
      "104 100\n",
      "63 100\n",
      "39 100\n",
      "90 100\n",
      "65 100\n",
      "57 100\n",
      "66 100\n",
      "53 100\n",
      "138 100\n",
      "54 100\n",
      "70 100\n",
      "94 100\n",
      "57 100\n",
      "73 100\n",
      "116 100\n",
      "35 100\n",
      "45 100\n",
      "85 100\n",
      "81 100\n",
      "54 100\n",
      "65 100\n",
      "57 100\n",
      "44 100\n",
      "63 100\n",
      "107 100\n",
      "116 100\n",
      "98 100\n",
      "141 100\n",
      "63 100\n",
      "44 100\n",
      "62 100\n",
      "46 100\n",
      "46 100\n",
      "70 100\n",
      "81 100\n",
      "46 100\n",
      "71 100\n",
      "54 100\n",
      "56 100\n",
      "46 100\n",
      "78 100\n",
      "69 100\n",
      "67 100\n",
      "95 100\n",
      "30 100\n",
      "59 100\n",
      "124 100\n",
      "54 100\n",
      "52 100\n",
      "120 100\n",
      "111 100\n",
      "32 100\n",
      "44 100\n",
      "65 100\n",
      "68 100\n",
      "95 100\n",
      "78 100\n",
      "31 100\n",
      "52 100\n",
      "69 100\n",
      "52 100\n",
      "49 100\n",
      "45 100\n",
      "44 100\n",
      "67 100\n",
      "99 100\n",
      "48 100\n",
      "41 100\n",
      "48 100\n",
      "157 100\n",
      "43 100\n",
      "37 100\n",
      "95 100\n",
      "34 100\n",
      "51 100\n",
      "32 100\n",
      "61 100\n",
      "76 100\n",
      "58 100\n",
      "83 100\n",
      "97 100\n",
      "51 100\n",
      "70 100\n",
      "62 100\n",
      "192 100\n",
      "88 100\n",
      "44 100\n",
      "104 100\n",
      "53 100\n",
      "63 100\n",
      "79 100\n",
      "77 100\n",
      "28 100\n",
      "46 100\n",
      "31 100\n",
      "65 100\n",
      "107 100\n",
      "44 100\n",
      "30 100\n",
      "97 100\n",
      "142 100\n",
      "28 100\n",
      "62 100\n",
      "90 100\n",
      "85 100\n",
      "98 100\n",
      "62 100\n",
      "52 100\n",
      "74 100\n",
      "70 100\n",
      "62 100\n",
      "62 100\n",
      "77 100\n",
      "75 100\n",
      "61 100\n",
      "87 100\n",
      "87 100\n",
      "91 100\n",
      "96 100\n",
      "47 100\n",
      "114 100\n",
      "37 100\n",
      "73 100\n",
      "72 100\n",
      "94 100\n",
      "53 100\n",
      "52 100\n",
      "129 100\n",
      "82 100\n",
      "96 100\n",
      "77 100\n",
      "110 100\n",
      "137 100\n",
      "156 100\n",
      "31 100\n",
      "68 100\n",
      "37 100\n",
      "91 100\n",
      "110 100\n",
      "40 100\n",
      "60 100\n",
      "41 100\n",
      "20 100\n",
      "66 100\n",
      "143 100\n",
      "172 100\n",
      "135 100\n",
      "95 100\n",
      "82 100\n",
      "83 100\n",
      "111 100\n",
      "53 100\n",
      "84 100\n",
      "49 100\n",
      "37 100\n",
      "94 100\n",
      "93 100\n",
      "53 100\n",
      "78 100\n",
      "89 100\n",
      "91 100\n",
      "134 100\n",
      "109 100\n",
      "60 100\n",
      "21 100\n",
      "76 100\n",
      "69 100\n",
      "56 100\n",
      "84 100\n",
      "88 100\n",
      "86 100\n",
      "37 100\n",
      "111 100\n",
      "50 100\n",
      "91 100\n",
      "37 100\n",
      "113 100\n",
      "41 100\n",
      "120 100\n",
      "111 100\n",
      "59 100\n",
      "112 100\n",
      "64 100\n",
      "42 100\n",
      "122 100\n",
      "61 100\n",
      "57 100\n",
      "43 100\n",
      "72 100\n",
      "114 100\n",
      "63 100\n",
      "85 100\n",
      "49 100\n",
      "80 100\n",
      "49 100\n",
      "60 100\n",
      "83 100\n",
      "90 100\n",
      "56 100\n",
      "155 100\n",
      "31 100\n",
      "83 100\n",
      "89 100\n",
      "79 100\n",
      "82 100\n",
      "94 100\n",
      "95 100\n",
      "54 100\n",
      "72 100\n",
      "63 100\n",
      "96 100\n",
      "84 100\n",
      "43 100\n",
      "75 100\n",
      "53 100\n",
      "50 100\n",
      "72 100\n",
      "132 100\n",
      "71 100\n",
      "109 100\n",
      "64 100\n",
      "70 100\n",
      "48 100\n",
      "71 100\n",
      "37 100\n",
      "96 100\n",
      "82 100\n",
      "110 100\n",
      "110 100\n",
      "54 100\n",
      "127 100\n",
      "33 100\n",
      "75 100\n",
      "45 100\n",
      "56 100\n",
      "77 100\n",
      "90 100\n",
      "121 100\n",
      "75 100\n",
      "65 100\n",
      "106 100\n",
      "51 100\n",
      "133 100\n",
      "130 100\n",
      "103 100\n",
      "56 100\n",
      "72 100\n",
      "70 100\n",
      "73 100\n",
      "102 100\n",
      "82 100\n",
      "71 100\n",
      "24 100\n",
      "109 100\n",
      "134 100\n",
      "58 100\n",
      "29 100\n",
      "64 100\n",
      "17 100\n",
      "48 100\n",
      "90 100\n",
      "85 100\n",
      "57 100\n",
      "63 100\n",
      "119 100\n",
      "111 100\n",
      "55 100\n",
      "43 100\n",
      "56 100\n",
      "68 100\n",
      "41 100\n",
      "98 100\n",
      "31 100\n",
      "120 100\n",
      "87 100\n",
      "74 100\n",
      "67 100\n",
      "122 100\n",
      "100 100\n",
      "108 100\n",
      "58 100\n",
      "118 100\n",
      "64 100\n",
      "74 100\n",
      "65 100\n",
      "89 100\n",
      "85 100\n",
      "69 100\n",
      "56 100\n",
      "79 100\n",
      "97 100\n",
      "24 100\n",
      "110 100\n",
      "26 100\n",
      "96 100\n",
      "100 100\n",
      "43 100\n",
      "121 100\n",
      "98 100\n",
      "46 100\n",
      "44 100\n",
      "43 100\n",
      "111 100\n",
      "27 100\n",
      "81 100\n",
      "100 100\n",
      "110 100\n",
      "68 100\n",
      "66 100\n",
      "103 100\n",
      "87 100\n",
      "128 100\n",
      "80 100\n",
      "73 100\n",
      "102 100\n",
      "124 100\n",
      "58 100\n",
      "51 100\n",
      "104 100\n",
      "54 100\n",
      "65 100\n",
      "71 100\n",
      "36 100\n",
      "71 100\n",
      "43 100\n",
      "59 100\n",
      "90 100\n",
      "69 100\n",
      "55 100\n",
      "87 100\n",
      "65 100\n",
      "46 100\n",
      "86 100\n",
      "112 100\n",
      "46 100\n",
      "74 100\n",
      "95 100\n",
      "69 100\n",
      "82 100\n",
      "48 100\n",
      "76 100\n",
      "48 100\n",
      "115 100\n",
      "36 100\n",
      "103 100\n",
      "79 100\n",
      "112 100\n",
      "61 100\n",
      "109 100\n",
      "68 100\n",
      "126 100\n",
      "46 100\n",
      "61 100\n",
      "76 100\n",
      "81 100\n",
      "44 100\n",
      "36 100\n",
      "89 100\n",
      "94 100\n",
      "124 100\n",
      "48 100\n",
      "118 100\n",
      "128 100\n",
      "80 100\n",
      "108 100\n",
      "88 100\n",
      "43 100\n",
      "64 100\n",
      "45 100\n",
      "185 100\n",
      "98 100\n",
      "63 100\n",
      "63 100\n",
      "76 100\n",
      "142 100\n",
      "87 100\n",
      "117 100\n",
      "77 100\n",
      "46 100\n",
      "66 100\n",
      "113 100\n",
      "47 100\n",
      "42 100\n",
      "38 100\n",
      "73 100\n",
      "85 100\n",
      "98 100\n",
      "193 100\n",
      "110 100\n",
      "82 100\n",
      "74 100\n",
      "53 100\n",
      "139 100\n",
      "94 100\n",
      "41 100\n",
      "170 100\n",
      "32 100\n",
      "28 100\n",
      "44 100\n",
      "96 100\n",
      "65 100\n",
      "98 100\n",
      "45 100\n",
      "73 100\n",
      "48 100\n",
      "121 100\n",
      "65 100\n",
      "53 100\n",
      "55 100\n",
      "44 100\n",
      "65 100\n",
      "86 100\n",
      "69 100\n",
      "66 100\n",
      "57 100\n",
      "63 100\n",
      "68 100\n",
      "43 100\n",
      "65 100\n",
      "96 100\n",
      "111 100\n",
      "47 100\n",
      "88 100\n",
      "68 100\n",
      "59 100\n",
      "83 100\n",
      "50 100\n",
      "63 100\n",
      "86 100\n",
      "100 100\n",
      "56 100\n",
      "88 100\n",
      "69 100\n",
      "80 100\n",
      "112 100\n",
      "45 100\n",
      "39 100\n",
      "155 100\n",
      "119 100\n",
      "122 100\n",
      "78 100\n",
      "67 100\n",
      "94 100\n",
      "80 100\n",
      "66 100\n",
      "50 100\n",
      "54 100\n",
      "93 100\n",
      "106 100\n",
      "188 100\n",
      "45 100\n",
      "56 100\n",
      "98 100\n",
      "62 100\n",
      "180 100\n",
      "126 100\n",
      "72 100\n",
      "39 100\n",
      "48 100\n",
      "78 100\n",
      "65 100\n",
      "90 100\n",
      "71 100\n",
      "71 100\n",
      "121 100\n",
      "172 100\n",
      "81 100\n",
      "127 100\n",
      "93 100\n",
      "183 100\n",
      "106 100\n",
      "92 100\n",
      "64 100\n",
      "75 100\n",
      "94 100\n",
      "101 100\n",
      "64 100\n",
      "98 100\n",
      "198 100\n",
      "38 100\n",
      "47 100\n",
      "47 100\n",
      "125 100\n",
      "43 100\n",
      "83 100\n",
      "109 100\n",
      "84 100\n",
      "49 100\n",
      "64 100\n",
      "77 100\n",
      "84 100\n",
      "84 100\n",
      "103 100\n",
      "86 100\n",
      "92 100\n",
      "112 100\n",
      "77 100\n",
      "48 100\n",
      "89 100\n",
      "117 100\n",
      "44 100\n",
      "43 100\n",
      "90 100\n",
      "64 100\n",
      "58 100\n",
      "75 100\n",
      "35 100\n",
      "119 100\n",
      "40 100\n",
      "46 100\n",
      "82 100\n",
      "77 100\n",
      "73 100\n",
      "62 100\n",
      "72 100\n",
      "49 100\n",
      "58 100\n",
      "47 100\n",
      "84 100\n",
      "25 100\n",
      "27 100\n",
      "45 100\n",
      "35 100\n",
      "31 100\n",
      "45 100\n",
      "97 100\n",
      "51 100\n",
      "55 100\n",
      "44 100\n",
      "75 100\n",
      "113 100\n",
      "71 100\n",
      "39 100\n",
      "72 100\n",
      "100 100\n",
      "69 100\n",
      "61 100\n",
      "89 100\n",
      "79 100\n",
      "59 100\n",
      "35 100\n",
      "75 100\n",
      "38 100\n",
      "46 100\n",
      "41 100\n",
      "54 100\n",
      "58 100\n",
      "57 100\n",
      "116 100\n",
      "118 100\n",
      "88 100\n",
      "49 100\n",
      "68 100\n",
      "57 100\n",
      "115 100\n",
      "65 100\n",
      "117 100\n",
      "26 100\n",
      "84 100\n",
      "42 100\n",
      "102 100\n",
      "134 100\n",
      "68 100\n",
      "79 100\n",
      "76 100\n",
      "79 100\n",
      "71 100\n",
      "85 100\n",
      "58 100\n",
      "43 100\n",
      "59 100\n",
      "58 100\n",
      "47 100\n",
      "34 100\n",
      "62 100\n",
      "49 100\n",
      "97 100\n",
      "38 100\n",
      "48 100\n",
      "91 100\n",
      "107 100\n",
      "45 100\n",
      "52 100\n",
      "104 100\n",
      "57 100\n",
      "36 100\n",
      "45 100\n",
      "85 100\n",
      "69 100\n",
      "83 100\n",
      "76 100\n",
      "87 100\n",
      "43 100\n",
      "84 100\n",
      "63 100\n",
      "82 100\n",
      "81 100\n",
      "52 100\n",
      "57 100\n",
      "54 100\n",
      "74 100\n",
      "61 100\n",
      "32 100\n",
      "79 100\n",
      "50 100\n",
      "45 100\n",
      "75 100\n",
      "55 100\n",
      "46 100\n",
      "109 100\n",
      "43 100\n",
      "103 100\n",
      "52 100\n",
      "37 100\n",
      "38 100\n",
      "51 100\n",
      "63 100\n",
      "63 100\n",
      "26 100\n",
      "76 100\n",
      "40 100\n",
      "104 100\n",
      "48 100\n",
      "41 100\n",
      "53 100\n",
      "78 100\n",
      "75 100\n",
      "96 100\n",
      "84 100\n",
      "38 100\n",
      "124 100\n",
      "61 100\n",
      "77 100\n",
      "95 100\n",
      "75 100\n",
      "57 100\n",
      "96 100\n",
      "85 100\n",
      "96 100\n",
      "62 100\n",
      "56 100\n",
      "83 100\n",
      "47 100\n",
      "74 100\n",
      "106 100\n",
      "32 100\n",
      "56 100\n",
      "29 100\n",
      "87 100\n",
      "38 100\n",
      "79 100\n",
      "62 100\n",
      "33 100\n",
      "106 100\n",
      "45 100\n",
      "58 100\n",
      "108 100\n",
      "75 100\n",
      "106 100\n",
      "57 100\n",
      "118 100\n",
      "71 100\n",
      "80 100\n",
      "57 100\n",
      "85 100\n",
      "46 100\n",
      "67 100\n",
      "72 100\n",
      "46 100\n",
      "114 100\n",
      "71 100\n",
      "51 100\n",
      "67 100\n",
      "56 100\n",
      "58 100\n",
      "83 100\n",
      "69 100\n",
      "32 100\n",
      "23 100\n",
      "101 100\n",
      "92 100\n",
      "54 100\n",
      "103 100\n",
      "36 100\n",
      "33 100\n",
      "47 100\n",
      "75 100\n",
      "42 100\n",
      "104 100\n",
      "66 100\n",
      "54 100\n",
      "69 100\n",
      "116 100\n",
      "123 100\n",
      "78 100\n",
      "76 100\n",
      "85 100\n",
      "106 100\n",
      "78 100\n",
      "56 100\n",
      "73 100\n",
      "55 100\n",
      "50 100\n",
      "79 100\n",
      "93 100\n",
      "32 100\n",
      "40 100\n",
      "113 100\n",
      "68 100\n",
      "95 100\n",
      "47 100\n",
      "50 100\n",
      "56 100\n",
      "82 100\n",
      "61 100\n",
      "80 100\n",
      "102 100\n",
      "48 100\n",
      "89 100\n",
      "116 100\n",
      "108 100\n",
      "64 100\n",
      "76 100\n",
      "54 100\n",
      "61 100\n",
      "82 100\n",
      "118 100\n",
      "88 100\n",
      "35 100\n",
      "50 100\n",
      "50 100\n",
      "41 100\n",
      "56 100\n",
      "78 100\n",
      "115 100\n",
      "74 100\n",
      "66 100\n",
      "47 100\n",
      "53 100\n",
      "63 100\n",
      "72 100\n",
      "99 100\n",
      "54 100\n",
      "105 100\n",
      "87 100\n",
      "60 100\n",
      "63 100\n",
      "42 100\n",
      "49 100\n",
      "23 100\n",
      "48 100\n",
      "84 100\n",
      "56 100\n",
      "41 100\n",
      "103 100\n",
      "92 100\n",
      "46 100\n",
      "40 100\n",
      "53 100\n",
      "113 100\n",
      "71 100\n",
      "72 100\n",
      "33 100\n",
      "60 100\n",
      "55 100\n",
      "38 100\n",
      "61 100\n",
      "48 100\n",
      "71 100\n",
      "42 100\n",
      "36 100\n",
      "51 100\n",
      "26 100\n",
      "91 100\n",
      "30 100\n",
      "62 100\n",
      "61 100\n",
      "57 100\n",
      "61 100\n",
      "39 100\n",
      "66 100\n",
      "76 100\n",
      "62 100\n",
      "99 100\n",
      "27 100\n",
      "32 100\n",
      "36 100\n",
      "72 100\n",
      "113 100\n",
      "72 100\n",
      "25 100\n",
      "96 100\n",
      "69 100\n",
      "68 100\n",
      "76 100\n",
      "66 100\n",
      "90 100\n",
      "87 100\n",
      "32 100\n",
      "34 100\n",
      "37 100\n",
      "41 100\n",
      "54 100\n",
      "45 100\n",
      "62 100\n",
      "58 100\n",
      "68 100\n",
      "107 100\n",
      "36 100\n",
      "72 100\n",
      "51 100\n",
      "115 100\n",
      "51 100\n",
      "79 100\n",
      "98 100\n",
      "93 100\n",
      "35 100\n",
      "110 100\n",
      "38 100\n",
      "73 100\n",
      "43 100\n",
      "100 100\n",
      "76 100\n",
      "47 100\n",
      "66 100\n",
      "68 100\n",
      "57 100\n",
      "42 100\n",
      "41 100\n",
      "30 100\n",
      "61 100\n",
      "108 100\n",
      "41 100\n",
      "113 100\n",
      "73 100\n",
      "42 100\n",
      "68 100\n",
      "96 100\n",
      "48 100\n",
      "112 100\n",
      "63 100\n",
      "35 100\n",
      "50 100\n",
      "116 100\n",
      "61 100\n",
      "82 100\n",
      "79 100\n",
      "40 100\n",
      "81 100\n",
      "90 100\n",
      "39 100\n",
      "85 100\n",
      "116 100\n",
      "81 100\n",
      "44 100\n",
      "89 100\n",
      "85 100\n",
      "54 100\n",
      "96 100\n",
      "61 100\n",
      "66 100\n",
      "98 100\n",
      "47 100\n",
      "101 100\n",
      "115 100\n",
      "88 100\n",
      "99 100\n",
      "81 100\n",
      "50 100\n",
      "85 100\n",
      "11 100\n",
      "33 100\n",
      "55 100\n",
      "66 100\n",
      "80 100\n",
      "97 100\n",
      "83 100\n",
      "30 100\n",
      "76 100\n",
      "47 100\n",
      "27 100\n",
      "118 100\n",
      "50 100\n",
      "73 100\n",
      "44 100\n",
      "72 100\n",
      "73 100\n",
      "118 100\n",
      "44 100\n",
      "24 100\n",
      "49 100\n",
      "70 100\n",
      "101 100\n",
      "68 100\n",
      "69 100\n",
      "96 100\n",
      "21 100\n",
      "48 100\n",
      "61 100\n",
      "65 100\n",
      "54 100\n",
      "38 100\n",
      "55 100\n",
      "30 100\n",
      "42 100\n",
      "53 100\n",
      "107 100\n",
      "84 100\n",
      "74 100\n",
      "41 100\n",
      "53 100\n",
      "52 100\n",
      "48 100\n",
      "87 100\n",
      "118 100\n",
      "47 100\n",
      "59 100\n",
      "78 100\n",
      "37 100\n",
      "68 100\n",
      "91 100\n",
      "67 100\n",
      "55 100\n",
      "97 100\n",
      "99 100\n",
      "60 100\n",
      "77 100\n",
      "40 100\n",
      "102 100\n",
      "64 100\n",
      "106 100\n",
      "46 100\n",
      "67 100\n",
      "60 100\n",
      "96 100\n",
      "107 100\n",
      "84 100\n",
      "90 100\n",
      "79 100\n",
      "111 100\n",
      "50 100\n",
      "89 100\n",
      "78 100\n",
      "37 100\n",
      "44 100\n",
      "76 100\n",
      "75 100\n",
      "52 100\n",
      "37 100\n",
      "79 100\n",
      "74 100\n",
      "57 100\n",
      "20 100\n",
      "20 100\n",
      "85 100\n",
      "30 100\n",
      "49 100\n",
      "52 100\n",
      "106 100\n",
      "45 100\n",
      "39 100\n",
      "83 100\n",
      "48 100\n",
      "76 100\n",
      "36 100\n",
      "37 100\n",
      "84 100\n",
      "58 100\n",
      "118 100\n",
      "58 100\n",
      "51 100\n",
      "62 100\n",
      "69 100\n",
      "61 100\n",
      "51 100\n",
      "91 100\n",
      "50 100\n",
      "50 100\n",
      "110 100\n",
      "80 100\n",
      "60 100\n",
      "117 100\n",
      "84 100\n",
      "101 100\n",
      "117 100\n",
      "114 100\n"
     ]
    }
   ],
   "source": [
    "# Are our sentence vector lengths consistent?\n",
    "for i, v in enumerate(x_vect_avg_train):\n",
    "    print(len(x.iloc[i]), len(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 Multiclass classification on tf-idf data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2350, 1605), (784, 1605))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train.shape,tfidf_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(scipy.sparse.csr.csr_matrix, pandas.core.series.Series)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tfidf_train),type(y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(tfidf_train,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784, 1605), (2350, 1605))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_test.shape,tfidf_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784,), (2350,))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test1.shape,y_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7536170212765958"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(tfidf_train,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35331632653061223"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(tfidf_test,y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, pandas.core.series.Series)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_pred),type(y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    210\n",
       "0    196\n",
       "3    194\n",
       "2    184\n",
       "Name: label_total_project_costs, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    205\n",
       "3    203\n",
       "2    195\n",
       "1    181\n",
       "dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds=pd.Series(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[74 50 44 28]\n",
      " [61 54 47 48]\n",
      " [38 44 62 40]\n",
      " [32 33 42 87]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test1, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Seaborn\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#sns.set(font_scale=1.5) # Increase font size\n",
    "\n",
    "#def plot_conf_mat(y_test, y_preds):\n",
    "  #  \"\"\"\n",
    "  #  Plots a confusion matrix using Seaborn's heatmap().\n",
    "  #  \"\"\"\n",
    "  #  fig, ax = plt.subplots(figsize=(3, 3))\n",
    "  #  ax = sns.heatmap(confusion_matrix(y_test, y_preds),\n",
    "    #                 annot=True, # Annotate the boxes\n",
    "   #                  cbar=False)\n",
    "   # plt.xlabel(\"true label\")\n",
    "    #plt.ylabel(\"predicted label\")\n",
    "    \n",
    "#plot_conf_mat(y_test1, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.38      0.37       196\n",
      "           1       0.30      0.26      0.28       210\n",
      "           2       0.32      0.34      0.33       184\n",
      "           3       0.43      0.45      0.44       194\n",
      "\n",
      "    accuracy                           0.35       784\n",
      "   macro avg       0.35      0.36      0.35       784\n",
      "weighted avg       0.35      0.35      0.35       784\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test1, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a hyperparameter grid for LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "np.random.seed(42)\n",
    "grid_model1= {\"C\": np.logspace(-4, 4, 20)}\n",
    "model1 = RandomizedSearchCV(LogisticRegression(),\n",
    "                                param_distributions=grid_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=LogisticRegression(),\n",
       "                   param_distributions={'C': array([1.00000000e-04, 2.63665090e-04, 6.95192796e-04, 1.83298071e-03,\n",
       "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04])})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(tfidf_train,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.23357214690901212}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6485106382978724"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.score(tfidf_train,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35586734693877553"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.score(tfidf_test,y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 Multiclass classifier one vs Rest on tf_idf data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33035714285714285"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(LinearSVC())\n",
    "clf.fit(tfidf_train,y_train1)\n",
    "clf.score(tfidf_test,y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.35      0.36       196\n",
      "           1       0.25      0.22      0.24       210\n",
      "           2       0.28      0.31      0.30       184\n",
      "           3       0.42      0.44      0.43       194\n",
      "\n",
      "    accuracy                           0.33       784\n",
      "   macro avg       0.33      0.33      0.33       784\n",
      "weighted avg       0.33      0.33      0.33       784\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds1=clf.predict(tfidf_test)\n",
    "print(classification_report(y_test1, y_preds1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34183673469387754"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(LinearSVC())\n",
    "clf.fit(tfidf_train,y_train2)\n",
    "clf.score(tfidf_test,y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8740425531914894"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(tfidf_train,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.40      0.40       230\n",
      "           1       0.26      0.23      0.25       181\n",
      "           2       0.30      0.29      0.29       190\n",
      "           3       0.39      0.43      0.41       183\n",
      "\n",
      "    accuracy                           0.34       784\n",
      "   macro avg       0.33      0.34      0.34       784\n",
      "weighted avg       0.34      0.34      0.34       784\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds2=clf.predict(tfidf_test)\n",
    "print(classification_report(y_test2, y_preds2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "grid_model2= {\"C\": np.logspace(-4, 4, 20)}\n",
    "model2 = RandomizedSearchCV(LogisticRegression(),\n",
    "                                param_distributions=grid_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=LogisticRegression(),\n",
       "                   param_distributions={'C': array([1.00000000e-04, 2.63665090e-04, 6.95192796e-04, 1.83298071e-03,\n",
       "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04])})"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(tfidf_train,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6634042553191489"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(tfidf_train,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3482142857142857"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(tfidf_test,y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 Regression on tf_idf data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(tfidf_train, y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7143156482922549"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(tfidf_train, y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.01738308548349"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(tfidf_test, y_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6958067141346277"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression().fit(tfidf_train, y_train4)\n",
    "reg.score(tfidf_train, y_train4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.8161842160780335"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(tfidf_test, y_test4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6836284869716645"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression().fit(tfidf_train, y_train5)\n",
    "reg.score(tfidf_train, y_train5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.9858233712527524"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(tfidf_test, y_test5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4 Logistic regression on two categories prediction and tf-idf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2350,), (2350, 1605))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train6.shape, tfidf_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(tfidf_train, y_train6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8076595744680851"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_model.score(tfidf_train,y_train6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6020408163265306"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_model.score(tfidf_test,y_test6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logistic_model.predict(tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.204081632653065"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "accuracy = accuracy_score(y_test6,y_pred)*100\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[180, 202],\n",
       "       [110, 292]], dtype=int64)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_mat = confusion_matrix(y_test6,y_pred)\n",
    "confusion_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a hyperparameter grid for LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "log_reg_grid = {\"C\": np.logspace(-4, 4, 20)}\n",
    "rs_log_reg = RandomizedSearchCV(LogisticRegression(),\n",
    "                                param_distributions=log_reg_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Atieh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=LogisticRegression(),\n",
       "                   param_distributions={'C': array([1.00000000e-04, 2.63665090e-04, 6.95192796e-04, 1.83298071e-03,\n",
       "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04])})"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_log_reg.fit(tfidf_train, y_train6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 11.288378916846883}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_log_reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8991489361702127"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_log_reg.score(tfidf_train, y_train6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5969387755102041"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_log_reg.score(tfidf_test, y_test6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.53      0.56       382\n",
      "           1       0.60      0.66      0.63       402\n",
      "\n",
      "    accuracy                           0.60       784\n",
      "   macro avg       0.60      0.60      0.59       784\n",
      "weighted avg       0.60      0.60      0.59       784\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds6=rs_log_reg.predict(tfidf_test)\n",
    "print(classification_report(y_test6, y_preds6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.5 Multiclass classification on word2vec data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2350, 2350)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_vect_train),len(y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2350"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vect_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, pandas.core.series.Series)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_vect_train),type(y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 784)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_vect_test),len(y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [162]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[0;32m      2\u001b[0m model10 \u001b[38;5;241m=\u001b[39m LogisticRegression(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel10\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_word2vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train1\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1508\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1506\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[1;32m-> 1508\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1510\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1513\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1514\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1515\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1516\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 581\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:964\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my cannot be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 964\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    979\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric)\n\u001b[0;32m    981\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    744\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(dtype, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    745\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 746\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    749\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    750\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2064\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2063\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 2064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model10 = LogisticRegression(random_state=42)\n",
    "model10.fit(x_train_word2vec,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
